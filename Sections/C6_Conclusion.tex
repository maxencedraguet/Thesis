\chapter{\color{oxfordblue} Conclusion and Outlook}\label{chap-Conclusion}
\ChapFrame
\vspace{-1cm}
This thesis follows a logical succession, with first the theory underpinning the modern edifice of particle physics presented in Chapter~\ref{chap-theory}. The \gls{sm} has been extensively validated by many experiments across the world, in particular by the ATLAS Collaboration using data collided by the \gls{lhc} as presented in Chapter~\ref{chapter-ATLAS}. Many properties of the discovered particle in 2012 have been confirmed to correspond to those of the predicted \gls{sm} Higgs boson. Nevertheless, the ATLAS Collaboration continues to systematically study the new particle in evermore challenging measurements, searching for any possible discrepancy between observations and theoretical predictions. These require state-of-the-art detectors and reconstruction software. At their core, particle physics analyses are challenging statistical data analyses that are well addressed by modern machine learning and artificial intelligence, as reviewed in Chapter~\ref{Chap-ML}. The recent progress in this field provides an exciting avenue of development for ATLAS, helping the Collaboration propel the performance of its software to new heights by designing effective network-based models. One such promising area of development concerns jet flavour tagging, which has continuously benefitted from the adoption and development of advanced \gls{ml} in recent years, as outlined in Chapter~\ref{chap-ftag}. GN2, the newest generation of taggers, relies on a single multimodal network exploiting a Transformer Encoder at its core, with multiple tasks targeted to distil expert knowledge in the network. The excellent performance obtained promises more refined measurements from the numerous analyses targetting heavy-flavour quarks in their final state during the ongoing Run 3 of the \gls{lhc}. \\

Two analyses benefitting starkly from flavour tagging are the \vhb\ and \vhc. These are now combined into the \vhbc\ analysis, described in Chapter~\ref{chap-VH}. At the time of writing, the analysis is in its last phase with final studies on the modelling and the fit framework, hence the results presented here are still blinded. Excitingly, great strides were made in the effort to observe the $H \rightarrow c\bar{c}$ decay and measure the $c$-quark Yukawa coupling. The expected upper limit on the signal strength has been reduced by a factor of 2.8 to 11.1 $\times$ \gls{sm} expectations, compared to the last published ATLAS result \cite{Collaboration:2721696}. Similarly, great progress was made in the measurement of the $H \rightarrow b\bar{b}$, with an expected signal strength sensitivity of 7.9 $\sigma$ corresponding to a 23\% improvement over the last ATLAS published result \cite{ATLAS:2021wqh}. For the first time, both production modes are expected to be observed in a $b\bar{b}$ decay mode, with respective significances of 5.5 $\sigma$ for $WH$ and 6.2 $\sigma$ for $ZH$. An \glsfirst{stxs} measurement of the different cross-sections of \vhb\ is also performed in stage 1.2.\\

To continue exploring the limit of our understanding in the particle physics realm, algorithmic and machine developments are required throughout the experiment. Collecting large datasets is crucial to analyses searching for rare signatures and performing precision measurements. This requires the detector to be operated in more challenging conditions: the price for higher instantaneous luminosity is more pile-up. The subdetectors must be upgraded to deal with this increased activity. Simultaneously to improving the hardware, the software of the ATLAS Collaboration must be upgraded to further push the sensitivity of the detector and deal with the new conditions. In this respect, flavour tagging benefited greatly from adopting advanced new \gls{nn} architecture such as the Transformer, but also from the multimodal input and multitask paradigms to pass expert knowledge. Future avenues of progress primarily consist of pursuing this path, adding further low-level input information and defining additional tasks to help the main classification objective. Across science and industry, modern machine learning plays a crucial role in this modernisation effort. This is particularly the case in \gls{hep}, where the large databases from collisions and simulations are effectively exploited to create effective and precise models. Such networks are trained for all the uses of the field: from generative \gls{ai} to effectively produced simulated samples, to deployed on \glspl{fpga} triggers, \gls{dl} to reconstruct physics objects from the rich set of low-level collected data, and finally \gls{ml} in analyses to improve signal discrimination from the backgrounds and help constrain the modelling of the different processes. 