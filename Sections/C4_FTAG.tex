\chapter{\color{oxfordblue} Flavour Tagging}\label{chap-ftag}
\ChapFrame

\textit{
This chapter is focused one of the essential task for the ATLAS experiment: identifying particles passing through the detector. This objective of assigning labels to reconstructed particles from measurements is called tagging. An important family of particles to be tagged are quarks, and disentangling which specific quark flavour should be associated with an observed signal is called flavour tagging. Free quarks and gluons hadronise as per the rules of \gls{qcd}, forming many particles that can themselves further decay. Such a dynamic results in an ensemble of particles radiated within a cone centred around the initial coloured particle, a structure referred to as a jet. This chapter introduces a computational method to tag jets, as labelled by the flavour of the initial parton. In particular, the different algorithms and methods relevant to this task that have been developed contemporaneously to this thesis project are reviewed, including the DIPS, DL1d, GN1, and GN2 models as well as early studies on the hyperparameter optimisation of GN2.
}

\section{Heavy-Flavour Jet Tagging}
A fundamental ingredient in any ATLAS analysis is the ability to correctly identify particles in the aftermath of a collision, from $\tau$-leptons, to $b$- and $c$-quarks, and gluons $g$. Having well-calibrated and optimally performing $b$- and $c$-tagging tools is of primary importance in studies of the Higgs boson couplings to $b$- and $c$-quarks. It is also critical for top quark measurements and in many searches of physics \glsfirst{bsm}. As described by the theory of \gls{qcd}, colour-charged objects, such as a $b$- or a $c$-quark, undergo hadronisation to form collections of colour-neutral hadrons. These hadrons, mostly $B$ for $b$-quark and $D$ for $c$-quark, are quasi-stable and further decay in the volume of the detector. Such a succession of decays leaves a collection of particles within a cone oriented in the direction of the original parton, an easily recognisable pattern referred to as a \textit{jet}. From an analysis of the complicated structure of the jet, the flavour of the initially decaying particle can be reconstructed. The labelling scheme chosen in this chapter is to label the jets based on the species of hadrons found: a $b$-jet must contain at least one $b$-hadron, a $c$-jet at least one $c$-hadron and no $b$-hadron, and if none of these hadrons are found the jet is said to be a light-jet, thereby grouping $u$-, $d$-, and $s$-quarks with gluons $g$. This is the task of \textit{flavour tagging}, and the tool to achieve this identification is called a \textit{flavour tagger}. The focus of this chapter is on the development of novel taggers to identify $b$- and $c$-jet for the ATLAS experiment during the 2020-2024 period, overlapping with the end of Run 2 (2015-2018) and the beginning of Run 3 (2022-2026). 

\subsection{Decay Topology}
When a $b$-quark is produced, such as in the aftermath of a hard scatter due to a proton-proton collision, it quickly undergoes the process of hadronisation to neutralise its free colour charge. This process leading free quarks and gluons to a final state of hadrons and leptons is intrinsically non-perturbative and can only be described with phenomenological models of fragmentation \cite{Webber:419784}. The family of $b$-hadrons is composed of different ensembles of a bottom quark $b$ with one or more lighter quarks. These include the $B$-mesons, mainly $B^0=d\bar{b}$, $B^-=\bar{u}b$, $B^+=u\bar{b}$, and the strange and charmed $B$-mesons, and baryons, such as the $\Lambda_b^0=udb$ \cite{ATL-PHYS-PUB-2014-008}. For $b$-quarks, the hadronisation process is hard and most ($\sim$ 75\%) of the quark momentum is passed to the $b$-hadron \cite{Webber:419784}. Tagging $b$-jets benefits from a particularly advantageous configuration: the $b$ is the lightest element of the third generation of quarks and must decay through a weak interaction flavour-changing process. Because of the relatively small \gls{sm} value of the $|V_{bc}|$ \gls{ckm} matrix element, decay processes involving a transition $b \rightarrow c$ are suppressed, giving $b$-hadrons a characteristically long proper lifetime $\tau_B \approx 1.5$ ps, corresponding to a proper decay length $c\tau_{B} \sim 450$ $\mu$m \cite{Tanabashi:2018oca}. In the laboratory frame and considering a boost of the $b$-hadron given by a Lorentz $\gamma$ factor ($\gamma > 1$) in the high energy limit $\beta = v/c \approx 1$, the distance travelled is \[d = \gamma \beta c \tau_B \approx \gamma c \tau_B.\] In this high energy limit, $\gamma \approx E_B / m_B$, where the $B$-hadron rest mass is in the range of 5 to 6 GeV. Consequently, a 50 GeV $b$-hadron decays at a distance of $d \approx 4.5$ mm from the primary vertex, which can be resolved using existing detector technology. This distance travelled increases with rising jet $p_T$, and at $p_T \sim$ 500 GeV even overpasses the first detector layer of the \gls{ibl} located at a distance of $\sim$33 mm from the centre of ATLAS, as shown in Figure~\ref{fig:bhaddecay}. The location of the hadron decay, called the \textit{\gls{sv}}, can therefore often be reconstructed with the ATLAS detector \cite{Aad:2019aic}. Some important variables describing the decay of hadrons are the \glspl{ip} $d_0$ and $z_0$ of the tracks left by charged particles emanating from the \gls{sv}. As shown in Figure~\ref{fig:bjet}, $d_0$ and $z_0$ are the transversal and longitudinal distances from the primary vertex to the perigee of the track. For a $b$-jet, the \glspl{ip} can be large thanks to the long lifetime of the associated hadron. On average, a $b$-hadron decays weakly to four or five charged stable particles \cite{ATL-PHYS-PUB-2014-008}. Another characteristic of $b$-jets is the likely presence of leptons in the jet cone, as $\sim$40\% of the $b$ and $c$-hadrons decays are semi-leptonic \cite{Tanabashi:2018oca}. \\

\begin{figure}[h!]
\center
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Images/FTAG/intro/jetIm.png}
  \caption{Representation of a $b$-jet \cite{bjetimage}.}
  \label{fig:bjet}
\end{minipage}
%\begin{minipage}{0.48\textwidth}
%  \centering
%  \includegraphics[width=\textwidth]{Images/FTAG/intro/bhaddecay.png}
%  \caption{$b$-hadron decay radius as a function of jet $p_T$ reconstructed for $b$-jets in a $Z'$ events with the IBL and pixel %layers indicated, from \cite{VanStroud:2869719}. Error bars show the standard deviation of $L_{xy}$ in each $p_T$ bin.} 
%  \label{fig:bhaddecay}
%\end{minipage}
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Images/FTAG/intro/bhaddecay2ada.png}
  \caption{$b$-hadron and $c$-hadron (labelled $D$-hadron) decay radius as a function of jet $p_T$ reconstructed for two $b$-jets or $c$-jets in $Z'$ events, adapted from \cite{ATL-PHYS-PUB-2018-025}. The IBL and first Pixel layer transverse distances are indicated as blue and orange dashed lines.} 
  \label{fig:bhaddecay}
\end{minipage}
\end{figure}

While $b$-jets benefit from an advantageous topology, tagging $c$-jets at ATLAS proves more challenging as they are at an intermediate-mass scale between light- and heavy-flavour jets. A $c$-jet must contain at least one $c$-hadron, from either a $D$-meson (e.g., $D^+=c\bar{d}$, $D^-=d\bar{c}$, $D^0=c\bar{u}$) or a $c$-baryon (e.g., $\Lambda_c^+=udc$). The average decay length for charged (neutral) $D$-mesons, $c\tau_D \sim 300$ $(100)$ $\mu$m \cite{Tanabashi:2018oca}, is smaller than for $b$-hadrons and is harder to resolve with the currently deployed tracker, as highlighted in Figure~\ref{fig:bhaddecay}. The decay chain of $b$-hadrons often includes a $c$-hadron, making a clean separation of $c$-jets from $b$-jets harder. Compared to $b$-jets, $c$-jets have a lower final state average charged particle multiplicity of 4. This lets $\tau$-jets easily be mistaken for $c$-jets, as these leptons can hadronically decay into a similar number of particles and appear as jets in the detector. Tagging $c$-jets is however becoming particularly important due to the focus on the challenging $H \rightarrow c\bar{c}$ search \cite{Aaboud:2018fhh, Collaboration:2721696, arXiv:2205.05550}, as presented in the analysis of Chapter~\ref{chap-VH}. 

\subsection{Flavour Tagging at ATLAS}
In ATLAS, a choice was made to centrally develop a tagger to be used throughout the collaboration. The tagger simultaneously performs $b$- and $c$-tagging, and the software stack and methods are continuously improved to meet the requirements of the physics program. Currently, all studied approaches rely on \gls{dl} methods, given their vastly superior effectiveness. As such, various models have been introduced, that can be split into two generations: 
\begin{enumerate}
  \item The DL1 family are \gls{dl} models built in a hierarchical way. These \gls{dl} methods rely on high-level features reconstructed by sub-algorithms based on physics variables, such as the tracks \glspl{ip}, and the reconstruction of secondary vertices \cite{ATL-PHYS-PUB-2015-022}. The most important models in this family are those including a \gls{dl} sub-model to analyse tracks with either a \gls{rnn} approach for \gls{dl1r} \cite{ATLAS:2017bcq}, leveraging the \gls{rnnip} sub-tagger \cite{ATL-PHYS-PUB-2017-003}, and a Deep Set approaches for \gls{dl1d}, leveraging the \gls{dips} sub-tagger \cite{ATL-PHYS-PUB-2020-014}. This last tagger is, at the moment of writing this thesis, the state-of-the-art calibrated tagger in the ATLAS software \cite{ATL-SOFT-PUB-2021-001}. Algorithms from this family were mainly developed for the end of Run 2 of the ATLAS experiment \cite{atlas:FTAGRUN2}, with \gls{dl1d} being developed before the start of Run 3.
  \item The GN family of taggers are built on more advanced \gls{dl} methods and moves away from the hierarchical approach of the DL1 family. These models directly analyse tracks and jet information with a unique powerful architecture. The GN family is based either on a full \glsfirst{gat} for \gls{gn1}, or a Transformer encoder for \gls{gn2} \cite{ATL-PHYS-PUB-2022-027, ATL-PLOT-FTAG-2023-01, duperrin2023flavour}. This streamlined algorithm pipeline greatly simplifies the maintenance and turnaround time for modifications, making the process of updating the taggers nimbler and easier to tailor to specific applications. The GN taggers greatly outperform the DL1 family and represent an exciting area of progress for future analysis requiring precise flavour jets tagging. \gls{gn2} is, at the time of writing, being calibrated and integrated into the ATLAS software stack, so that it can be used for Run 3 analyses \cite{ATL-SOFT-PUB-2021-001}.  
\end{enumerate}

\begin{figure}[h!]
  \center
  \includegraphics[width=0.8\textwidth]{Images/FTAG/storyFtag.png}
  \caption{Comparison of the performance of flavour tagging models introduced through the years \cite{ATL-PLOT-FTAG-2023-01}. Light and $c$-jet rejections (inverse of the mis-tag efficiency) are plotted for different taggers at a fixed $b$-jet tagging efficiency of 70\% on a $t\bar{t}$ evaluation set. The multiplicative factors in the bars are with respect to the bare DL1 model performance.} 
  \label{fig:storyFtag}
\end{figure}

A historical perspective on the evolution of performance attained with the different taggers mentioned is presented in Figure~\ref{fig:storyFtag}, showing a remarkable and consistent increase in light- and $c$-jet rejections at a fixed $b$-tagging efficiency of 70\% evaluated a $t\bar{t}$-simulated dataset. The analysis presented in the latter part of this thesis was carried out from 2021 to 2024 and was therefore restricted to tools and methods available to the experimental team during this period. As such, due to the need to calibrate the GN taggers as explained later in Section \ref{chap-calibration} of this chapter, the analysis was constrained to use the DL1 family. The taggers described in this chapter have been integrated into the ATLAS software \cite{ATL-SOFT-PUB-2021-001}. 

\subsection{Datasets}\label{ftagdatasets}
ATLAS analyses scan a $p_T$ spectrum that covers a wide range of energies due to the fractional momentum of the partons. To train models able to perform on this large phase space, two training datasets are typically combined and described in this section. The datasets simulate proton-proton collisions at a centre of mass energy $\sqrt{s}$ = 13 TeV. The lower $p_T$ phase space is filled with simulated \gls{sm} top-antitop quark pair production $t\bar{t}$ events, where at least one $W$ boson produced decays leptonically. A \gls{bsm} $Z'$ process is used for the higher momentum region. The latter simulates a modified $Z$ boson with an increased mass to generate a flat jet $p_T$ spectrum up to 6 TeV. These $Z'$-bosons decay in similar proportions to a pair of $b$, $c$, and light-jets. All simulations include realistic effects present in the real data such as \gls{pu}, with an average value of $ \langle\mu\rangle = 40$. Other effects included in the simulations are the detector response from prior and posterior bunch crossing (in-time \gls{pu}), as well as the activity from the rest of the event (\gls{ue}). \\

Events in the $t\bar{t}$ sample are simulated using \textsc{POWHEGBOX V2} generators to Next-to-Leading Order (NLO) in the strong coupling constant $\alpha_s$ \cite{PaoloNason_2004, StefanoFrixione_2007, StefanoFrixione_20072, POWHEGBOX}. The hard scatter matrix element is computed for proton-proton collision with the \textsc{NNPDF3.0NNLO} set of parton distribution functions (PDF) \cite{PDFLHCrun2}, and the simulated hard scatter events are interfaced with \textsc{PYTHIA 8.230} \cite{SJOSTRAND2015159} using the A14 parameter tune \cite{ATL-PHYS-PUB-2014-021} and the \textsc{NNPDF2.3LO} PDFs for the parton shower, hadronisation, and underlying event simulations \cite{BALL2013244}. Studies in Refs \cite{ATL-PHYS-PUB-2016-020, ATL-PHYS-PUB-2020-023} showed these choices correctly model the top quark $p_T$ and the number of additional jets in the event, with the $h_{\textrm{damp}}$ parameter set at 1.5 the mass of the top quark $m_{\textrm{top}} = 172.5$ GeV. The $Z'$ events are fully simulated with \textsc{PYTHIA 8.212}, A14 tune and the \textsc{NNPDF2.3LO} PDFs. The decays of $b$- and $c$-hadrons are performed by \textsc{EvtGEN} v1.6.0 \cite{LANGE2001152}. \\

The detector reconstruction effect of ATLAS and the modelling of the interaction between long-lived hadrons and the detector material are simulated with a dedicated software \cite{ATLASSimulationInfra} built on GEANT4 \cite{Agostinelli:602040}. Jets are selected in the phase space region defined by $|\eta| < 2.5$ and $p_T > 20$ GeV, with no overlapping allowed with prompt generator-level $e$ or $\mu$ from the $W$ decay. Pile-up contamination is further reduced by an additional selection using the \glsfirst{jvt} algorithm at a tight operating point for jets with $p_T < 60$ GeV and $|\eta| < 2.4$ \cite{ATLAS-CONF-2014-018}. Tracks are associated with jets using a $\Delta R$ association cone of width decreasing with $p_T$, such that $\Delta R \approx 0.45$ at $p_T =$ 20 GeV and $\Delta R \approx 0.25$ at $p_T > 200$ GeV. Tracks within the cone of several jets are associated with the jet minimising the angular distance $\Delta R(\textrm{track, jet})$. The label of the jet is inferred from the presence of a truth-level hadron within the cone $\Delta R(\textrm{hadron, jet}) < 0.3$ centred around the jet axis.

\section{DL1 Family of Taggers: DL1r \& DL1d}
This family of taggers is built with a hierarchical approach, combining low-level algorithms that are independently optimised into a final \gls{dnn} network of a few layers to output the predictions. Not all low-level modules are based on \gls{dl}, with some instead directly implementing physics-motivated algorithms. They consist of \cite{atlas:FTAGRUN2, Paganini:2289214}:
\begin{itemize}
  \item \gls{ip} likelihood discriminants: IP2D and IP3D (summarised IPxD) are likelihood-ratio templates in 2D and 3D to assign flavour-discriminating weights based, respectively, on the transversal and global impact parameters significances\footnote{Corresponding to the reweighted \gls{ip} variables by their respective uncertainties.} $S_{d_0}$ (35 bins) and $S_{z_0}$ (20 bins) of the tracks, and 14 bins of tracks categorisation for IP3D \cite{ATLAS:2017bcq}. For the three flavours, this results in $35 \times 20 \times 14 \times 3 = 29,400$ final bins, with each probability computed per track. The likelihood assigned to the jet assumes the tracks are independent, and is therefore calculated as the product of the per-track likelihoods. A discriminant is derived from the conditional log-likelihood, e.g., $D^b_{IP3D,f} = \sum_{i \in \textrm{tracks}} \log (p_b^i / p_f^i)$, to discriminate $b$-jets from $f$-jets ($f= c$ or light) \cite{ATL-PHYS-PUB-2015-022}.
  \item Track collection analyser: either with \gls{rnnip} \cite{ATL-PHYS-PUB-2017-003} or \gls{dips} \cite{ATL-PHYS-PUB-2020-014}. These are \gls{dl} approaches to extract discrimination information on the set of tracks associated with a jet. They importantly do not assume that tracks are independent. These taggers are further described later in this chapter. 
  \item \gls{sv1}: combining a secondary vertex finder and a tagger to offer flavour discrimination information \cite{atlas:FTAGRUN2}. The former, based on the \textsc{VKalVrt} vertex reconstruction package \cite{Kostyukhin:685551}, returns a list of candidate secondary vertices with measured quantities assigned to each vertex. The latter derives jet weights based on discriminative variables and computes properties of the \gls{sv}, such as its mass. 
  \item Jet Fitter: a vertexing algorithm based on a Kalman filter to reconstruct the topology and fit the decay chain \gls{pv} $\rightarrow$ $B$ $\rightarrow$ $D$, with the assumption that the vertices of the weakly decaying $B$- and $D$-hadrons tend to align with the \gls{pv} \cite{atlas:FTAGRUN2, ATL-PHYS-PUB-2018-025}. 
\end{itemize}

\begin{figure}[h!]
  \centerline{
  \begin{minipage}[c]{0.4\textwidth}
      \includegraphics[scale=0.5]{Images/Algorithms}
    \end{minipage}
  \begin{minipage}[c]{0.6\textwidth}
      \caption{The algorithms for flavour tagging in the DL1 family. High-level taggers are in dark blue, track-based taggers in light blue, and vertex taggers in white.}
      \label{fig:algo}
    \end{minipage}
  }
\end{figure}

The outputs of these low-level algorithms, as well as certain jet-level variables such as $p_T$ and $\eta$ are then passed as input to a high-level tagger consisting of a fully-connected \gls{nn} called \gls{dl1r} or \gls{dl1d}, respectively if \gls{rnnip} or \gls{dips} is used. The input vector is made of 44-45 features. This high-level tagger outputs three scores $p_X$ for the analysed jet corresponding to the $b$-, $c$-, or light-flavour (indicated with the letter $u$) probabilities such that $p_b + p_c + p_u = 1$. A $b$-tagging discriminant $D_b$ is then derived by computing a scaled log-likelihood ratio 
\begin{equation}\label{bdisc}
D_b = \log \frac{p_b}{f^b_c \times p_c + (1 - f^b_c) \times p_u},
\end{equation}
where $f^b_c$ is the $c$-fraction, a parameter that can be modified to tweak the relative importance of the rejected flavours. The analogous $c$-tagging discriminant $D_c$ relying on the $f^c_b$ $b$-fraction parameter is 
\begin{equation}\label{cdisc}
D_c = \log \frac{p_c}{f^c_b \times p_b + (1 - f^c_b) \times p_u}.
\end{equation}

A jet is $X$-tagged if the $D_X$ discriminant score is above a set threshold constant $c_{wp}$, defining a \gls{wp} with a unique configuration of signal and background (mis-tag) efficiencies. In this context, the efficiency $\epsilon^X_Y$ for $Y$-flavour jets to be $X$-tagged and the corresponding rejection $\mathcal{R}^X_Y$ are respectively defined as:
\begin{equation}
\epsilon^X_Y = \frac{N^{X-tagged}_{Y-jets}}{N_{Y-jets}} \quad \textrm{and} \quad \mathcal{R}^X_Y = \frac{1}{\epsilon^X_Y},
\end{equation}
where $N^{X-tagged}_{Y-jets}$ and $N_{Y-jets}$ are respectively the number of $X$-tagged $Y$-flavoured jets and the total number of $Y$-flavoured jets. The $f$-rejection is the inverse mis-tag efficiency of flavour $f$.  \\

These high-level models are trained on \gls{mc} simulated data samples, as mentioned in Section \ref{ftagdatasets}, and need to be calibrated on real data to deliver an unbiased estimate, by deriving \glspl{sf} weights correcting the predictions for each jet as described in Section \ref{chap-calibration}. Uncertainties are derived on the predicted score and passed along to analyses using the tool. The novel algorithm of this family introduced in this work is the \gls{dl1d} tagger, which relies on the \gls{dips} sub-tagger to extract correlations between the tracks.  

\subsection{RNNIP}
The \gls{rnnip} tagger runs on arbitrary-length input sequences made of track features, as ordered by the absolute transverse \gls{ip} significance $|S_{d_0}|$, to extract tagging information from correlations between tracks \cite{ATL-PHYS-PUB-2017-003}. The vector of track features, described in greater detail in Table~\ref{tab:rnnipVar}, includes the transverse and longitudinal impact parameter significances, the jet $p_T$ fraction, the distance between the tracks and the jet axis, and a learned 2D embedding of the quality of the tracks \cite{Paganini:2289214}. \gls{rnnip} outputs a probability $p_X$ for the jet to belong to flavour $X$ $\in$ [$b$, $c$, light, $\tau$].

\begin{figure}[h!]
  \center
  \includegraphics[scale=0.6]{Images/FTAG/rnnip_structure.png}
  \caption{Diagram of the \gls{rnnip} tagger \cite{Paganini:2289214}. The input consists of track features augmented with an embedding of track categories. Tracks are then ordered by absolute transverse \gls{ip} significance and fed through an \gls{lstm} core. The unrolled sequence from this \gls{lstm} is padded to a fixed size and processed by a \gls{dnn} to output the per-flavour probabilities.} 
  \label{fig:rnnipModel}
\end{figure}

The architecture of \gls{rnnip} is a \gls{rnn}-based model leveraging an \gls{lstm} core, as depicted in Figure~\ref{fig:rnnipModel}. The arbitrary-length sequence fed as input is mapped by the \gls{lstm} cell with a 100-unit hidden layer into a 50-dimensional vector. This vector is then processed by a 20-unit fully-connected feed-forward neural network outputing the per-flavour probabilities by computing the softmax of the last layer's output. To avoid overfitting, a dropout value of 0.2 is applied to the \gls{lstm} cell. 

\begin{table}[h]
  \begin{center}
      \begin{tabular}{C{3cm}|C{13cm}} 
      	 \hline \hline
          Track Variables & Description  \\ \hline \hline
          $S_{d_0}$      & Lifetime signed transverse \gls{ip} significance $d_0 / \sigma_{d_0}$, with $d_0$ the transverse \gls{ip} and $\sigma_{d_0}$ the error on $d_0$. If the perigee is in front (behind) the \gls{pv} with respect to the jet direction, the sign is positive (negative). \\ \hline
          $S_{z_0}$      & Lifetime signed longitudinal \gls{ip} significance $z_0 / \sigma_{z_0}$, with $z_0$ the longitudinal \gls{ip} and $\sigma_{z_0}$ the error on $z_0$. A sign is assigned as per the prescription of $S_{d_0}$. \\ \hline
          $p_T^{\textrm{frac}}$   & Fraction of the reconstructed jet $p_T^{\textrm{jet}}$ carried by the track $p_T^{\textrm{frac}} = p_T^{\textrm{track}} / p_T^{\textrm{jet}}$. \\ \hline
          $\Delta R$(track, jet) & Geometrical distance in 2D angle between the track direction and jet axis $\Delta R = \sqrt{(\phi_{\textrm{track}} - \phi_{\textrm{jet}})^2 + (\eta_{\textrm{track} - \eta_{\textrm{jet}}})^2}$. \\ \hline
          Category       & 2D representation of the track quality learnt by an embedding layer. The categorisation is based on the number of observed, expected and missing hits in the different layers of the tracker (silicon pixel and strip detectors) \cite{ATL-PHYS-PUB-2015-022}.  \\ \hline
      \end{tabular}
    \caption{Track variables passed to the initial version of the \gls{rnnip} model \cite{ATL-PHYS-PUB-2017-003}. Later versions removed the category embedding and added the per-track hit information shown for \gls{dips} in Table~\ref{tab:dipsVar}.}
    \label{tab:rnnipVar}
  \end{center}
\end{table}

\gls{rnnip} is designed to capture correlations between the tracks of a jet, an important insight explicitly missing from the \gls{ip}-based discriminant of IP2D and IP3D due to the factorisation of the likelihood. Some degree of correlation is expected between tracks, as these can emerge from the same secondary or tertiary vertex of the displaced decays in $b$- and $c$-jets. \gls{rnnip} removes the cumbersome procedure to build likelihood templates, which demands a large amount of data to scale to finer bin resolution and is computationally expensive due to the number of bins scaling exponentially with the number of variables. \gls{rnnip} is effective at building a discriminant, delivering superior performances to the \gls{ip}-based approaches with only $\sim$40 \% of the parameters - 11,636 trainable parameters for \gls{rnnip} \cite{Paganini:2289214}.

\subsection{DIPS}
The \gls{dips} tagger based on the Deep Set architecture \cite{NIPS2017f22e4747}, as depicted in Figure~\ref{fig:dipsModel}, is an alternative to \gls{rnnip} to model the correlations between an arbitrary number of tracks \cite{ATL-PHYS-PUB-2020-014}. As introduced in Chapter \ref{chapter-GNN}, such a model is composed of two fully-connected feed-forward neural networks. A first \gls{dnn} called the \textit{track network} $\Phi$ maps each track feature vector - similar to the input of \gls{rnnip} - to a latent space representing the nodes of a graph. The representations of each track in this latent space are then pooled by a simple summation operation - representing the unweighted edges of a fully connected graph - and given as input to a secondary \gls{dnn}, called the \textit{jet network} $F$. This latter network outputs the predicted probability $p_X$ for the jet to belong to flavour $X$ $\in$ [$b$, $c$, light, $\tau$]. This last network represents the global attribute of the graph $u$, in the notation of Chapter \ref{chapter-GNN}. 
In summary, \gls{dips} computes the following equation on the set of track features $\{ p_i \}$, with $i = 1, ..., N$ for arbitrarily-sized jets of $N$ tracks
\begin{equation}
  DIPS( \{p_1, ..., p_N \} ) = F\left( \sum_{i=1}^N \Phi(p_i) \right)
\end{equation}
to output the per-flavour probabilities. The separation of computation into a per-track embedding and a per-jet processing after a size-independent pooling performed by the summation operator allows the model to process unordered sets of variable size. The track features used as inputs are described in Table~\ref{tab:dipsVar}, with only the top 15 tracks as ranked by decreasing $S_{d_0}$ considered. \\

\begin{figure}[h!]
  \center
  \includegraphics[scale=0.6]{Images/FTAG/dips_structure.png}
  \caption{Diagram of the \gls{dips} tagger for flavour tagging \cite{ATL-PHYS-PUB-2020-014}. The input consists of a set of $N$ tracks, each represented by a feature vector. Each track is embedded by a \gls{dnn} track network $\Phi$ into a fixed-dimension vector. All embedded track vectors are then pooled by summation to a fixed-size vector. The last step is to process this vector with another \gls{dnn} jet network $F$ outputing the per-flavour probabilities. The number and width of layers presented here correspond to the nominal architecture.} 
  \label{fig:dipsModel}
\end{figure}

\begin{table}[h]
  \begin{center}
      \begin{tabular}{C{3cm}|C{13cm}} 
      	 \hline \hline
          Variables & Description  \\ \hline
          $S_{d_0}$      & Lifetime signed transverse \gls{ip} significance $d_0 / \sigma_{d_0}$, with $d_0$ the transverse \gls{ip} and $\sigma_{d_0}$ the error on $d_0$. If the perigee is in front (behind) the \gls{pv} with respect to the jet direction, the sign is positive (negative). \\ \hline
          $S_{z_0}$      & Lifetime signed longitudinal \gls{ip} significance $z_0 / \sigma_{z_0}$, with $z_0$ the longitudinal \gls{ip} and $\sigma_{z_0}$ the error on $z_0$. A sign is assigned as per the prescription of $S_{d_0}$. \\ \hline
          $\log p_T^{\textrm{frac}}$   & Logarithm of the fraction of the reconstructed jet $p_T^{\textrm{jet}}$ carried by the track $\log p_T^{\textrm{frac}} = \log p_T^{\textrm{track}} / p_T^{\textrm{jet}}$. \\ \hline
          $\log \Delta R$(track, jet) & Logarithm of the geometrical distance in 2D angle between the track direction and jet axis $\log \Delta R = \log \sqrt{(\phi_{\textrm{track}} - \phi_{\textrm{jet}})^2 + (\eta_{\textrm{track} - \eta_{\textrm{jet}}})^2}$. \\ \hline
          IBL hits      & Number of hits recorded in the \gls{ibl} - 0, 1, or 2. \\ \hline
          PIX1 hits       & Number of hits in the innermost pixel layer, after the \gls{ibl} - 0, 1, or 2.  \\ \hline
          Shared IBL hits & Number of hits in the \gls{ibl} that are shared by more than one track. \\ \hline
          Split IBL hits  & Number of split hits in the \gls{ibl}, that are created by multiple charged particles. \\ \hline
          nPixHits        & Total number of hits in all the pixel layers.\\ \hline
          Shared pixel hits & Number of shared hits in the pixel layers.\\ \hline
          Split pixel hits  & Number of split hits in the pixel layers.\\ \hline
          nSCTHits          & Total number of hits in the \gls{sct} layers. \\ \hline
          Shared SCT hits   & Number of shared hits in the \gls{sct} layers.\\ \hline \hline
      \end{tabular}
      \caption{Track variables passed to the \gls{dips} model and later versions of the \gls{rnnip} model \cite{ATL-PHYS-PUB-2020-014}. Compared to the initial \gls{rnnip} variables of Table~\ref{tab:rnnipVar}, the $p_T^{\textrm{frac}}$ and $\Delta R$ are passed as log values to reduce the magnitude of the long tail observed at large values and improve the training time. Shared hits are hits used by multiple tracks without being classified as split by a dedicated cluster-splitting \gls{nn} \cite{ATLAS-tracks-algo}.}
    \label{tab:dipsVar}
  \end{center}
\end{table}

This approach has several advantages over \gls{rnnip}, mainly the physically motivated permutation-invariance of the input and the improved training and evaluation time thanks to a more parallelisable architecture, as the track embedding performed by $\Phi$ can be massively parallelised on \glspl{gpu}. These motivations are translated in an appreciable performance delivered by \gls{dips}, which globally outperforms \gls{rnnip} while operating at a reduced computational cost \cite{ATL-PHYS-PUB-2020-014}. The performance can be assessed from Figure~\ref{fig:dipsrnnipPerf}, presenting the \gls{roc} curves for baselines trainings of \gls{dips} and \gls{rnnip} in terms of light- and $c$-rejection for $b$-jet tagging on $t\bar{t}$ evaluation sample. \\

\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{Images/FTAG/dipsrnnipL.png}
      \caption{Light-rejection.} 
      \label{fig:dipsrnnipPerfL}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{Images/FTAG/dipsrnnipC.png}
      \caption{$c$-rejection.} 
      \label{fig:dipsrnnipPerfC}
  \end{subfigure}
  \caption{Light- (left) and $c$-rejection (right) as a function of $b$-jet tagging efficiency for \gls{rnnip} (green) and \gls{dips} (purple), taken from \cite{ATL-PHYS-PUB-2020-014}. The curves and error bands show the mean and standard deviation of the rejections for 5 trainings per algorithm. The bottom panel shows the ratio to \gls{rnnip}.}
  \label{fig:dipsrnnipPerf}
\end{figure} 

%The optimisation campaign focused on three aspects of the \gls{dips} network: the architecture of the two \gls{nn}, the track selection, and the set of track features used as input in addition to those of Table~\ref{tab:dipsVar}. Regarding architecture, a grid search over various possible values for the number of layers in $\Phi$ and $F$, the number of nodes, and the dimension of the track embedding space showed no significant performance change. The selected architecture is:
%\begin{itemize}
%  \item Track network $\Phi$: three layers of 100, 100, and 128 units applied to each track. 
%  \item Jet network $F$: four layers of size 100, 100, 100, 30 before the final output of size dictated by the number of %flavours to identify (3 or 4 typically). 
%\end{itemize}
%To regularise and avoid overfitting, both batch normalisation and dropout were tested with the former observed to give %better results. \\ 


%  \begin{figure}[h!]
%    \centering
%    \begin{subfigure}[b]{0.48\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{Images/FTAG/dipsOptL.png}
%        \caption{Light-rejection.} 
%        \label{fig:dipsOptRocL}
%    \end{subfigure}
%    \hfill
%    \begin{subfigure}[b]{0.48\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{Images/FTAG/dipsOptL.png}
%        \caption{$c$-rejection.} 
%        \label{fig:dipsOptRocC}
%    \end{subfigure}
%    \caption{Light- (left) and $c$-rejection (right) as a function of $b$-jet tagging efficiency for different \gls{dips} model, with the baseline (nominal) \gls{dips} in purple, the loosened track selection in blue, and the fully optimised \gls{dips} in orange, from \cite{ATL-PHYS-PUB-2020-014}. The curve and error bands show, respectively, the mean and standard deviation of the rejections for 5 trainings per algorithm with different initial random seeds. The bottom panel shows the ratio to the baseline \gls{dips}, showing a clear performance gain from the two-step optimisation procedure at all $b$-jet efficiency considered.}
%    \label{fig:dipsOptRoc}
%  \end{figure} 

The training times on the same \gls{gpu} hardware for a 48k parameters \gls{dips} model is 78 $\pm$ 4 seconds per epoch, while a 47k parameters \gls{rnnip} requires roughly thrice as much, 241 $\pm$ 14 seconds per epoch \cite{ATL-PHYS-PUB-2020-014}. The faster training time allowed the Collaboration to focus on optimisation studies of the hyperparameters. An important additional observation was that loosening the track selection criteria led to a performance improvement. For \gls{rnnip}, IP2D, and IP3D, the selected tracks must pass the following quality selection: $\geq$ 8 hits in the silicon layers, $\leq$ 2 missing hits in the silicon layers, $\geq$ 1 hit in the pixel detector, $\leq$ 1 hit shared by multiple tracks, $p_T$ > 1 GeV, $|d_0|$ < 1 mm, and $|z_0 \textrm{ sin}(\theta)|$ < 1.5 mm. For \gls{dips}, a looser track selection increasing the acceptance of the last three cuts is preferable, modifying the nominal selection in the following way: $p_T$ > 0.5 GeV, $|d_0|$ < 3.5 mm, and $|z_0 \textrm{ sin}(\theta)|$ < 5 mm \cite{ATL-PHYS-PUB-2020-014}. Loosening the selection and keeping the top 25 tracks as ranked by decreasing $S_{d_0}$ to capture more tracks from heavy-flavour decays were observed to lead to a significant improvement in performance for jets with $p_T < 250$ GeV for \gls{dips}. From an \gls{ml} viewpoint, a larger set of input information with more noise can still prove beneficial if the underlying model is complex enough to capture useful features in the noisy data, that would otherwise be erased by a more stringent selection. Some studies on interpreting the performance of \gls{dips} are summarised in Appendix~\ref{app-DIPS-perf}. % The performance gain for loosened selection \gls{dips} is displayed in the \gls{roc} curves of Figure~\ref{fig:dipsOptRoc}. Clear benefits are also obtained when adding additional track features as input on top of the looser selection, as shown by the orange curve of Figure~\ref{fig:dipsOptRoc}, which plots the performance of a loose track selection \gls{dips} trained with the per-track \gls{ip} parameters $d_0$ and $z_0$ in addition to the features of Table~\ref{tab:dipsVar}.\\

\subsection{Training of DIPS with Variable Radius Jets for Run 3}\label{chapter:dipsVRtrain}
The physics program of the ATLAS Collaboration covers a wide range of analyses, targeting different topologies and processes at different energies. Concerning flavour tagging, a particularly relevant aspect is the energy or transverse momenta of the jets to label. Flavour taggers are extremely sensitive to the dynamic of the underlying events. At higher energies, corresponding to higher momenta of the hadronised quark or gluon, the jet constituents emanating from the decaying parton tend to be more collimated in the same direction, as they have to share a large initial amount of energy between themselves. This topology confounds tracks and blends the rich internal jet dynamics in the measured signature, making track separation and secondary or tertiary vertex identification more difficult. Analyses targeting jets from hadronic or semileptonic decays of heavy particles, such as the top $t$-quark, Higgs $H$, or the gauge vector $W$ /$Z$ bosons, can easily produce such highly energetic or \textit{boosted} jets.  \\

So far in this chapter, jets have always referred to the object as reconstructed by the anti-$k_T$ algorithm with a fixed radius $R = 0.4$ applied to PFlow objects, as introduced in Chapter \ref{chapter-ATLAS}. This reconstruction method proves robust in the hadron collider setting as it both leads to suitably-shaped jet structure and \gls{pu}-resistant properties. The fixed radius however becomes a hurdle to reconstruct boosted jets, as the average radius of a jet decreases with energy due to the collimation of the jet content. The angular separation $\Delta R$ between the products of a decaying particle $X$ of large mass $m_X$ scales inversely to the transverse momentum \cite{ATLAS:largeRjet}: 
\begin{equation}\label{eq:sizeJet}
  \Delta R \approx \frac{2 m_X}{p_T^X}.
\end{equation}
At low $p_T^X$, the individually produced particles from the decay are sufficiently separated to be reconstructed as individual objects, hence the \textit{resolved} regime label \cite{ATLAS:2016hcf}. For example, a non-boosted Higgs decaying to a $b\bar{b}$ pair can be reconstructed as two $b$-jets with small $R$ = 0.4. At higher momentum, however, the content of the decay is collimated and overlaps: this is the \textit{boosted} regime. The decaying particle $X$ in such a regime is typically reconstructed as a single large-radius jets, to catch the different underlying jets, for example with the anti-$k_T$ method with radius $R = 1.0$. Using such a fixed large radius overestimates the size of boosted jets which are easily contaminated by the \gls{pu}, as well as the underlying event and initial-state radiations.  \\

Another approach to reconstruct jets from boosted objects decay is the \gls{vr} jet algorithm \cite{vrJetPaper}, as introduced in Chapter \ref{chapter-ATLAS}. \gls{vr} jets have a size that scales with the inverse of the reconstructed jet momentum, thus correctly following the expected dynamic of Equation \ref{eq:sizeJet}. Such a significant change to the jet reconstruction is bound to have an impact on algorithms learning structure from the jet contents, as is the case of all deep learning-based taggers presented in this chapter. These models must therefore be fine-tuned to this new jet type for optimal performance, which is the focus of this section. For the \gls{vr}-training, the dataset is composed of three samples simulating proton-proton collisions at $\sqrt{s} = 13$ with the following fractions:
\begin{itemize}
  \item 85 \% of jets are sampled from the $t\bar{t}$ with a maximal $p_T$ of 400 GeV. At least one of the $W$ boson from the $t$-quark is required to decay leptonically.
  \item 7.5\% are sampled from $Z'$ events, where an exotic boson $Z'$ decays as $Z' \rightarrow q\bar{q} \textrm{ or } \tau \bar{\tau}$, with a variable $Z'$ mass to generate a flat $p_T$ spectrum extending the $p_T$-range of the jets studied up to 4 TeV. These jets are required to have a $p_T > 150$ GeV.
  \item 7.5\% are sampled from a simulated graviton process to also increase the range towards higher momenta. These jets are required to have a $p_T > 150$ GeV.
\end{itemize}

The simulation process is similar to that introduced in Section \ref{ftagdatasets}. Appendix Figure~\ref{apfig:vrjetdist} displays the jet $p_T$ and $|\eta|$ distributions for the hybrid sample as well as the individual samples it is based upon, for a total of 40 $\times$ $10^6$ jets per flavour in \{$b$, $c$, light\}. To reach such high statistics, importance sampling with replacement is used to upsample the limited amount of $c$-jets while using all available $b$- and downsampling light-jets. A particularity of the processing is the requirement for the $p_T$ and $|\eta|$ spectra to be equally distributed for all jet flavours so that these features arising from inherent physics effects in the specific processes simulated cannot be used by the model to discriminate between flavours. Jets of different flavours are selected to match a specific target distribution. The importance sampling weights are derived by first computing the ratio of the targeted 2D distribution to the per flavour one. Weights above 1 indicate jets in the $i, j$ bin have to be oversampled, while values lower than 1 indicate they should be downsampled. Jets are then iteratively sampled until the sampled distribution of each flavour individually matches the target distribution. As displayed in Appendix Figure~\ref{apfig:vrjetdisth} for which the target is $b$-jets, the thus constructed distributions have the same $p_T$ and $|\eta|$ distributions for all flavours. This work introduced the first implementation of the importance sampling method, now widely used to develop flavour tagging tools leveraging the full statistical power of the simulations. \\ 
 
\begin{figure}
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    %\includegraphics[scale=0.43]{Images/FTAG/VRDips/ROC/ttb.png}
    \includegraphics[width=\textwidth]{Images/FTAG/VRDips/ROC/ttb.png}
    \caption{$b$-tagging on \ttb.}
    \label{fig:dipsVRROCtt}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDips/ROC/zpb.png}
    \caption{$b$-tagging on $Z'$.}
    \label{fig:dipsVRROCzp}
  \end{subfigure} \\
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDips/ROC/ttc.png}
    \caption{$c$-tagging on \ttb.}
    \label{fig:dipsVRROCttc}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDips/ROC/zpc.png}
    \caption{$c$-tagging on $Z'$.}
    \label{fig:dipsVRROCzpc}
  \end{subfigure}
  \caption{ROC curves for $b$-tagging and $c$-tagging on 300k jets test samples of \ttb\ (left) and $Z'$ (right). Models displayed are the \gls{vr}-jets \gls{dips} in blue, the PFlow-trained \gls{dips} in orange, and \gls{rnnip} trained on \gls{vr}-jets from the previous software release in green.}
  \label{fig:dipsVRROC}
\end{figure}

The optimised \gls{dips} model with 62,167 learnable parameters from the previous section was trained for 200 epochs on 4 Quadro RTX 8000 \glspl{gpu}. The learning rate started at 0.001 and was reduced by a factor of 0.8 on plateaus of 3 epochs, with a batch size of 15k jets, batch normalisation, and a dropout rate of 0.1 for the $F$ network. The training proved stable with no signs of overtraining. The model at the epoch giving the smallest loss on a validation set of 300k jets as well as the best light- and $c$-rejections at a fixed 77\% $b$-tagging efficiency is selected. Figures~\ref{fig:dipsVRROC} and \ref{fig:dipsVRROCgrav} show the \gls{roc} curves for $b$- and $c$-tagging of the best \gls{dips} model on \gls{vr}-jets (blue), as well as some comparison to the \gls{dips} model trained on PFlow jets (orange) and \gls{rnnip} trained on \gls{vr}-jets from the previous software release R21 (green). These \gls{roc} plots show, on the $x$-axis, the $b$-tagging efficiency ($\epsilon^b_b$) versus, on the $y$-axis, the rejection $\mathcal{R}^b_Y$ for $Y \in$ [$c$, light], or equivalently for $c$-tagging swapping $b \leftrightarrow c$.\\

\begin{figure}
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDips/ROC/grb.png}
    \caption{$b$-tagging.}
    \label{fig:dipsVRROCgr}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDips/ROC/grc.png}
    \caption{$c$-tagging.}
    \label{fig:dipsVRROCgrc}
  \end{subfigure}
  \caption{ROC curves for $b$- and $c$-tagging on 300k jets of the graviton samples, similar to Figure~\ref{fig:dipsVRROC}.}
  \label{fig:dipsVRROCgrav}
\end{figure}

Training \gls{dips} on a dedicated set of \gls{vr}-jets improves performance compared to relying on the PFlow-trained version, as observed by comparing the blue (\gls{vr}-trained \gls{dips}) to orange curves (PFlow-trained \gls{dips}). At a $b$-tagging efficiency of 77\%, the light-rejection of the PFlow-trained \gls{dips} is $\sim$40\% lower. However, the $c$-rejection does not benefit as much, being either on par or even lower for the \gls{vr}-trained \gls{dips} on the $t\bar{t}$ samples. This difference in performance indicates an inappropriate choice of $f_c$ value for the $b$-tagging discriminant of the \gls{vr}-trained \gls{dips}. A so-called \textit{flavour fraction scans}, displaying the rejections at a fixed tagging efficiency for different values of the flavour fraction, can lead to a better choice for a balanced improvement in both background jet rejections. However, \gls{dips} probabilities are not meant to be used directly in a discriminant but rather passed on to the high-level algorithm \gls{dl1d}, hence this optimisation is reserved for the final model as presented in Section~\ref{sec:VRdl1dTrain}. Figures \ref{fig:dipsVRROCttc} to \ref{fig:dipsVRROCgrc} lead to similar conclusions for $c$-tagging.

\subsection{Training of DL1d and DL1r with PFlow for Run 3}
This work presents the first ATLAS study of the retraining of \gls{dl1r} on a new software release for the Run 3 of the \gls{lhc}, and the first training of \gls{dl1d} including the \gls{dips} sub-tagger in the high-level flavour tagging tool. Other important novelties of this work are the possible inclusion of $\tau$-jets in the \gls{dl1} model's predictions and the importance sampling technique to process high-statistics training datasets introduced in the previous section. The interest in including $\tau$ stems from their tendency to be misclassified as $c$-jets when hadronically decaying, as both particles commonly leave three to four particles in the detector. The resulting taggers are observed to efficiently identify $\tau$-jets thereby providing a new way to perform $\tau$-identification and improving $c$-jet tagging.\\ % However, due to the widespread use of the \gls{ftag} algorithms and the difficulties arising in calibrating a tagger with excellent rejection against $\tau$-jets, these are not included in the default version of the tagger nor the results shown here, but are actively under study for the new generation of tagger in the GN family. \\ % Problem: reference to tau tagging but no plots ... add them?

Two samples, the $t\bar{t}$ and $Z'$ from proton-proton collisions at $\sqrt{s} = 13$, are simulated and combined in the datasets, as described in Section \ref{ftagdatasets}. For both samples, PFlow jets are reconstructed using the anti-$k_T$ algorithm with radius $R = 0.4$. These two samples are combined into a single \textit{hybrid} sample to train the taggers, with 70\% of the total number of jets coming from $t\bar{t}$ and the remaining from the $Z'$. The $t\bar{t}$ and $Z'$ samples cover, respectively, a low- and high-$p_T$ region based on a reconstructed $b$-hadron $p_T$ separation threshold of 250 GeV for $b$-jets and a jet $p_T$ of 250 GeV for non-$b$-jets. They are re-sampled to have the same $p_T-|\eta|$ distributions. The relative proportion of each sample was chosen to avoid any discontinuity in the $p_T$ spectrum at their junction, as evidenced in Figure~\ref{fig:distTraining}. The total statistics available for the R22 training is $25 \times 10^{6}$ jets per flavour. The final evaluation of the performance of a trained tagger is performed on separate test sets of both processes and unfolded over the flavours. The $t\bar{t}$ and $Z'$ samples for validation and testing are each made of 1 million jets and are not downsampled to have the same [$p_T - \eta$] distribution nor the same yield of different flavours. \\

\begin{figure}[h!]
  \center
  \includegraphics[width=0.48\textwidth]{Images/FTAG/DL1d/ptdist.png}
  \includegraphics[width=0.48\textwidth]{Images/FTAG/DL1d/etadist.png}
  \caption{The $p_T$ (left - in MeV) and $|\eta|$ distributions of the resampled $b$-, $c$-, and light-jets in, respectively, blue, orange, and green. The three sets are resampled to have the same $p_T-|\eta|$ 2D distributions. The flat $p_T$ spectrum extending up to several TeV is due to the exotic $Z'$ process generated with varying mass, starting at 150 GeV. The large peak at lower $p_T$ is the $t\bar{t}$-process. These sets have 8.3 million jets per flavour.} 
  \label{fig:distTraining}
\end{figure}

%ATLAS flavour tagging tools are widely used across the Collaboration. It is therefore essential for the taggers not to learn specific features of the processes simulated but to focus on the inherent differences between the studied flavours to generalise to other processes. An effective way to limit the importance of the simulated processes is to downsample the hybrid sample in [$p_T - \eta$] bins to have the same number of $b$-, $c$-, and light-jets in each 2D bin. This removes the distinction of kinematic phase space between each flavour due to the process-specific physics. To avoid biasing the output of the tagger towards the most likely flavours in the process, each jet flavour is also required to be equally likely in the training set, a requirement satisfied by having the same yield of $b$-, $c$-, and light-jets. Applying this technique, the total statistics available for the R22 training is of $25 \times 10^{6}$ jets per flavour for training. The $t\bar{t}$ and $Z'$ samples for validation and testing are each made of 1 million jets and are not downsampled to have the same [$p_T - \eta$] distribution nor the same yield of different flavours: they represent a realistic distribution of the underlying processes. The main limitation when downsampling is the $c$-jets statistics, as all $c$-jets from the $t\bar{t}$ process are selected which limits the amount of $b$- and light-jet that can be taken. This process is extremely wasteful, using only 17\% (11\%) of all available $b$-jets (light-jets) in the $t\bar{t}$ sample.\\

Training is performed with the \textsc{Umami} software \cite{UmamiCite} based on TensorFlow \cite{tensorflow2015-whitepaper} for 300 epochs with a variable learning rate schedule and the default network structure adopted in the previously released \gls{dl1r}: 8 fully connected \gls{nn} of smoothly-decreasing sizes in [256, 128, 60, 48, 36, 24, 12, 6] with \gls{relu} activation leading to a final softmax layer producing the predicted probabilities for each flavour. The models at an epoch offering the best combined results in terms of $b$-tagging efficiency and rejection from $b$-jets on the validation set are selected for further analysis. Every training converged to a fixed set of performance values, with no overtraining occurring. Several modifications to the model architecture, list of input variables, and preprocessing and training procedures have been explored, with no significant gain observed. 
The conclusion driven by the lack of improvements from these attempts is that models built on this simple \gls{dnn} structure with such a large dataset are already likely saturating their performance. To establish a meaningful benchmark for the newly trained taggers, the performance of the then recommended \gls{dl1r} tagger, trained and evaluated on an analogous set of samples from the previous software release is included in the following results under the label \textit{Recom. \gls{dl1r}}. A first look at the new family of taggers is also advertised by plotting the performance of a pre-release \gls{gn1} tagger, although this is discussed in further detail in the next Section~\ref{chap:GN}. 

%\begin{itemize}
%\item The preprocessing steps were revised to reduce the size of the evaluation sets for the benefit of the training statistics. A dual approach, downsampling light-jets and upsampling $c$-jets to the $b$-jets [$p_T - \eta$], has also been implemented. As previously described, this approach based on importance sampling with replacement enforces the same $p_T$ and $|\eta|$ distributions for the different flavours. While the performance of the majority classes was observed to improve, the efficiency at tagging the upsampled minority class ($c$-jets) was slightly lower. This trade-off can be compensated by modifying the flavour fractions and thus does not result in any significant performance change. This is likely due to the model saturating its performance given the large dataset already available. Other models, such as those from the GN family that have more parameters, have however been observed to make gains from the importance sampling approach.
%\item Several modifications to the list of input features have been attempted, with no clear advantage uncovered. Adding pile-up information (the actual number of interactions per crossing and the number of primary vertices were tested) was not observed to have an impact on the tagging efficiency. Adding other variables from \gls{sv1} or JetFitter was also not observed to improve performance. However, a positive observation is that the IP2D and IP3D taggers can both be safely removed without impacting the performance, as the information they add is now better covered by the \gls{dips} sub-tagger, thereby reducing the list of sub-taggers to maintain and simplifying the architecture.
%\item The structure of the network and its training procedure, leveraging transfer learning. Using samples produced with the previous ATLAS software release (R21) to pre-train the model was not observed to deliver a boost in performance when training on the new release (R22). Changing the size of the network and the batch size was also not observed to have a visible effect.
%\end{itemize}


\begin{figure}[h!]
  \centering
  \centerline{
  \includegraphics[scale=0.45]{Images/FTAG/DL1d/ROC/ttb.png}
  \includegraphics[scale=0.45]{Images/FTAG/DL1d/ROC/zpb.png}
  }
  \caption{Performance for $b$-tagging with a flavour fraction of $f^b_c = 0.018$. Left: $t\bar{t}$; right: $Z'$. Top: ROC curves; centre: ratio of $c$-jets rejection from $b$-jets relative to the R22-retrained DL1r; bottom: same ratio for light-jets rejection. The recommended DL1r from the previous release is in blue. The new release DL1d is in orange and GN1 is in green.}
  \label{fig:DL1dtt}
  \bigskip
  \centerline{
  \includegraphics[scale=0.45]{Images/FTAG/DL1d/ROC/ttc.png}
  \includegraphics[scale=0.45]{Images/FTAG/DL1d/ROC/zpc.png}
  }
  \caption{Performance for $c$-tagging with a flavour fraction of $f^c_b = 0.2$. Left: $t\bar{t}$; right: $Z'$. Top: ROC curves; centre: ratio of $b$-jets rejection from $c$-jets relative to the R22-retrained DL1r; bottom: same ratio for light-jets rejection. The recommended DL1r from the previous release is in blue. The new release DL1d is in orange and GN1 is in green.}
  \label{fig:DL1dz}
\end{figure}

\paragraph{}Figure~\ref{fig:DL1dtt} presents the \gls{roc} curves on the $t\bar{t}$ (left) and $Z'$ (right) test samples for $b$-tagging. These \gls{roc} plots are similar to those of Figure~\ref{fig:dipsVRROC}. The two bottom sub-plots present the ratio of the c-jet and light-jet rejection curves to the blue ones. This blue curve is the recommended \gls{dl1r} performance and serves as the baseline of the comparison, while the new tagger \gls{dl1d} is plotted in orange. Figure~\ref{fig:DL1dz} shows the same plots for $c$-tagging, with respect to $b$- and light-jet rejections. The important observation is the clear gain obtained when replacing \gls{rnnip} with \gls{dips}. Both the $b$- and $c$-tagging performance of \gls{dl1d} dominate the \gls{dl1r} versions, with a significant improvement in background flavour rejection for all tagging efficiency considered, as summarised in Table~\ref{tab:max-perf}. The largest performance improvement is obtained for $b$-tagging on the $t\bar{t}$ process, at lower jet momenta. This latter points to a dynamical behaviour of the \gls{dips} sub-tagger that can be traced back to the looser jet selection. Higher momentum jets are more likely to have a larger set of tracks and these tracks tend to be closer to each other due to relativistic boosting. The looser selection forces the \gls{dips} model to sift through a noisier set of tracks. This brings lesser gains in performance at higher momentum, while an improvement is obtained at lower momentum from the good geometrical separation and smaller initial set.  \\


\begin{table}[h]
  \begin{center}
      \begin{tabular}{C{2cm}|cc} 
      	 \hline \hline
          \multicolumn{3}{c}{$b$-tagging on $t\bar{t}$} \\ \hline
          WP & $c$-rejection  & light-rejection  \\ \hline
          60\%   & +26\% & +73\% \\ 
          70\%   & +19\% & +56\% \\ 
          77\%   & +12\% & +41\% \\ 
          85\%   & +7\%   & +32\% \\ \hline
          \multicolumn{3}{c}{} \\
           \hline  \hline
           \multicolumn{3}{c}{$c$-tagging on $t\bar{t}$} \\ \hline
          WP & $b$-rejection  & light-rejection  \\ \hline
          25\%   & +26\% & +5\% \\
          30\%   & +25\% & +9\% \\
          40\%   & +22\% & +12\% \\
          50\%   & +18\% & +15\% \\ \hline \hline
      \end{tabular}
      \quad
       \begin{tabular}{C{2cm}|cc} 
       	 \hline  \hline
          \multicolumn{3}{c}{$b$-tagging on $Z'$} \\ \hline
          WP & $c$-rejection  & light-rejection  \\ \hline
          60\%   & +19\% & +43\% \\
          70\%   & +10\% & +32\% \\
          77\%   & +9\%  & +26\% \\
          85\%   & +6\%  & +19\% \\ \hline
          \multicolumn{3}{c}{} \\
           \hline  \hline
           \multicolumn{3}{c}{$c$-tagging on $Z'$} \\ \hline
          WP & $b$-rejection  & light-rejection  \\ \hline
          25\%   & +12\% & +22\% \\
          30\%   & +11\% & +19\% \\
          40\%   & +8\%   & +14\% \\
          50\%   & +7\%   & +10\% \\ \hline  \hline
      \end{tabular}
    \caption{The change in background flavour rejections of \gls{dl1d} relative to \gls{dl1r} at various tagging efficiencies, both trained on the new release. Top: $b$-tagging ($f^b_c = 0.018$); bottom: $c$-tagging ($f^c_b = 0.2$); left: $t\bar{t}$; right: $Z'$.}
    \label{tab:max-perf}
  \end{center}
\end{table}

The light-rejection from $b$-jets \gls{roc} curve in Figure~\ref{fig:DL1dtt} traces an elbow at high $b$-jet efficiencies. This effect is also present in the $b$-rejection from $c$-tagging in Figure~\ref{fig:DL1dz}. Both correspond to a set of, respectively, light-jets and $b$-jets that do not overlap with the $b$-jets $b$-tagging and $c$-jets $c$-tagging discriminants distributions, as shown in Figures \ref{fig:scoreDL1dtt} and \ref{fig:scoreDL1dz}. These ``background`` jets are easily removed from the core set of ``signal'' jets due to inherent differences between the flavours and the discrete nature of some sub-taggers used. \\

In Figures \ref{fig:DL1dtt} and \ref{fig:DL1dz}, a GN-like tagger trained on 20 million jets from the new family base on \gls{gnn} that was in development at the time is introduced: \gls{gn1} \cite{ATL-PHYS-PUB-2022-027}. This model is based on a graph attention network (\gls{gat}) directly processing low-level inputs, thereby diverging from the traditional ATLAS flavour tagging philosophy of combining several low-level sub-taggers into a high-level one, such as in \gls{dl1d}. As exemplified in this plot, the method significantly improves the performance and is explored in further detail in Section~\ref{chap:GN}. \\

The background rejections of the various taggers for $b$-tagging ($c$-tagging) as a function of the jet transverse momentum $p_T$ at an inclusive $b$-efficiency of 70\% ($c$-efficiency of 30\%) per region displayed are shown in Figure~\ref{fig:ptDL1dtt} (Figure~\ref{fig:ptDL1dz}). Throughout the $p_T$ range considered, \gls{dl1d} outperforms the \gls{dl1r} tagger. The low $p_T$ $b$-rejection from $c$-jets is noticeably better for the newly trained tagger compared to \gls{dl1r}. The discontinuity of the rejections between the two processes arises from the inclusive $b$-tagging efficiency being computed inclusively per region and not exclusively for the whole range.

%
\begin{center}
  \begin{figure}[h!]
  %\vspace{-0.2cm}
  \centerline{
  \includegraphics[scale=0.5]{Images/FTAG/DL1d/ROC/scores_DL1_ttbar_300.png}
  \includegraphics[scale=0.5]{Images/FTAG/DL1d/ROC/scores_DL1_zp_300.png}
  }
  \caption{Distribution of \gls{dl1d} $b$-tagging discriminant with $f_c = 0.018$ for the different jet flavours, evaluated on $t\bar{t}$ (left) and $Z'$ (right).}
  \label{fig:scoreDL1dtt}
  \centerline{
  \includegraphics[scale=0.5]{Images/FTAG/DL1d/ROC/scores_DL1_ttbar_c_299.png}
  \includegraphics[scale=0.5]{Images/FTAG/DL1d/ROC/scores_DL1_zp_c_299.png}
  }
  %\vspace{-0.3cm}
  \caption{Distribution of \gls{dl1d} $c$-tagging discriminant with $f_b = 0.2$ for the different jet flavours, evaluated on $t\bar{t}$ (left) and $Z'$ (right).}
  \label{fig:scoreDL1dz}
  \end{figure}
\end{center}

\clearpage
%
\begin{center}
\begin{figure}[h!]
\vspace{-0.6cm}
\centerline{
  \includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/ttbc.png}
  \includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/ttbu.png}
}
\centerline{
  \includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/zpbc.png}
  \includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/zpbu.png}
}
\caption{Background flavour rejections at a fixed $b$-tagging efficiency of 70\% (per region shown) for the various taggers. Top: $t\bar{t}$; bottom: $Z'$; left: $c$-rejection; right: light-rejection. For each plot, the bottom panel presents the ratio to the recommended \gls{dl1r}.}
\label{fig:ptDL1dtt}
\bigskip
\centerline{
\includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/ttcb.png}
\includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/ttcu.png}}
\centerline{
\includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/zpcb.png}
\includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/zpcu.png}
}
\caption{Background flavour rejections at a fixed $c$-tagging efficiency of 30\% (per region shown) for the various taggers. Top: $t\bar{t}$; bottom: $Z'$; left: $b$-rejection; right: light-rejection. For each plot, the bottom panel presents the ratio to the recommended \gls{dl1r}.}
\label{fig:ptDL1dz}
\end{figure}
\end{center}

The \gls{dl1d} model was quickly integrated into the ATLAS software thanks to its similarities with \gls{dl1r}. Its fast calibration led to its rapid introduction to the Collaboration and deployment in early Run 3 analyses \cite{ATLAS-CONF-2022-070}. To exploit the full potential of the trained model and to cater to the specific needs of individual analyses, several working points are centrally defined and calibrated. An important parameter to control the relative importance of the jet classes to be rejected with the discriminants of Equations \ref{bdisc} and \ref{cdisc}, light and $c$ for $b$-tagging and light and $b$ for $c$-tagging, are the flavour fractions $f_c$ and $f_b$. Naturally, there is a trade-off: for $b$-tagging, a larger $f_c$-value favours a better $c$-rejection at the cost of a degraded light-rejection. To measure this dependency, flavour fractions scans are performed at a fixed $b$-tagging ($c$-tagging) efficiency of 77\% (30\%) in Figure~\ref{fig:DL1dscanfb} (Figure~\ref{fig:DL1dscanfc}). \\

% here
%\vspace{-1cm}
\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{\textwidth}
      \centering
      \includegraphics[width=0.49\textwidth]{Images/FTAG/DL1d/extra_plots/contour_fraction_ttbar_300.pdf}
      \includegraphics[width=0.49\textwidth]{Images/FTAG/DL1d/extra_plots/contour_fraction_zp_300.pdf}
      \caption{Flavour fraction $f_c^b$ scan for $b$-tagging: left is $t\bar{t}$ and right $Z'$ test samples.} 
      \label{fig:DL1dscanfb}
  \end{subfigure}\\
  \begin{subfigure}[b]{\textwidth}
    \centering % NEED TO CORRECT THE WP for the c-tagging case
    \includegraphics[width=0.49\textwidth]{Images/FTAG/DL1d/extra_plots/contour_fraction_c_ttbar_299.pdf}
    \includegraphics[width=0.49\textwidth]{Images/FTAG/DL1d/extra_plots/contour_fraction_c_zp_299.pdf}
    \caption{Flavour fraction $f_b^c$ scan for $c$-tagging: left is $t\bar{t}$ and right $Z'$ test samples.} 
    \label{fig:DL1dscanfc}
\end{subfigure}
  \caption{The flavour fraction scans of the DL1d model. The chosen values are marked on the curves, displaying on the $y$-axis the $c$-rejection ($b$-rejection) for $b$-tagging ($c$-tagging) vs the light-rejection on the $x$ axis at a fixed operating point of 77\% (33\%). Increasing $f_c$ or $f_b$ shifts the marker upwards along the curves. }
  \label{fig:DL1dscanf}
\end{figure} 

An effective technique to measure the relative importance of the different variables is to quantify their contribution to the output using Shapley values. This technique for model explanation calculates the average contribution of each input to the output \cite{Rozemberczki2022TheSV}. Figures~\ref{fig:DL1dshapb} and \ref{fig:DL1dshapc} present the outcome of applying this framework, as proposed in Ref. \cite{NIPS2017_7062} to approximate the Shapley values of the inputs to the $b$-tagging $D_b$ and $c$-tagging $D_c$ discriminants of \gls{dl1d} respectively. These so-called \textit{beeswarm} plots measure the impact of the evidence on the output of the model for each input feature. The plots display how each feature' Shapley value modifies the discriminant by moving from a prior background-data distribution expectation to the final model prediction using the real feature. A set of test datapoints of the targeted jet distributions\footnote{e.g., $b$-jets for $b$-tagging.} are sampled and, for each, a prior expectation was randomly sampled for the initial test. The impact of using the real value in the prediction was then measured. Positive Shapley values indicate variables having an increasing effect on the discriminant, thereby helping either $b$- or $c$ tagging as per the plot considered. Each data point is coloured on a gradient scale from low feature value in blue to high feature value in red, and the dots pile up to indicate the density of the distribution. A feature that has more weight of its Shapley values distribution at larger values of the feature can be expected to help the model in identifying the main flavour of jets. Conversely, if the Shapley values are negative for large values of the feature, the feature value should be lowered for the model discriminant to improve.

%\begin{figure}[h!]
\begin{sidewaysfigure}
  \centering
  \includegraphics[scale=0.7]{Images/FTAG/DL1d/Shap/ttb.png}
  \includegraphics[scale=0.7]{Images/FTAG/DL1d/Shap/zpb.png}
  \caption{Shapley values of the different inputs variables of DL1d for $b$-tagging, $t\bar{t}$ on the left and $Z'$ on the right. High feature values are marked as red dots, while low feature values are blue.} 
  \label{fig:DL1dshapb}
\end{sidewaysfigure} 


%\begin{figure}[h!]
\begin{sidewaysfigure}
  \centering
  \includegraphics[scale=0.7]{Images/FTAG/DL1d/Shap/ttc.png}
  \includegraphics[scale=0.7]{Images/FTAG/DL1d/Shap/zpc.png}
  \caption{Shapley values of the different inputs variables of DL1d for $c$-tagging, $t\bar{t}$ on the left and $Z'$ on the right. High feature values are marked as red dots, while low feature values are blue.} 
  \label{fig:DL1dshapc}
\end{sidewaysfigure} 

\paragraph{}Inspecting Figure~\ref{fig:DL1dshapb} reveals some interesting patterns in the \gls{dl1d} network for the task of $b$-tagging. The most important family of features for this task are the \gls{dips} probabilities, with higher values of $p_b$ correctly identifying the jet as $b$ while higher values of $p_c$ and $p_{\textrm{light}}$ (noted $p_u$) have the opposite effect. The number of 2-track pairs from \gls{sv1} and some JetFitter variables - the mass of the vertex, the energy fraction and the number of tracks at the vertex - are also highlighted as important features. These observations are in line with a physics-based reasoning about the dynamic behind the jet: $b$-jets are expected to have a large charged particle multiplicity and the exchange of momentum is hard, with the $b$-hadron taking most of the $b$-quark momentum. Some other interesting features to consider are the ones formatted as  ``algoName\_isDefaults'': they encode whether the base-method ``algoName'' is activated (0 - blue) or not and thus defaulting (1 - red) for each jet. Interestingly, most of the occurrences of a defaulting behaviour of \gls{sv1} and JetFitter are associated with a negative Shapley value, demonstrating the validity of the physics reasoning behind these methods and their active contributions to $b$-tagging. IPxD variables generally score low in the ranking, indicating these methods contribute little to the model predictions and can be safely removed, an observation confirmed by direct optimisation of the input features set. Contrasting the Shapley values for $t\bar{t}$ (left) and $Z'$ (right), the same variables roughly rank in the same order with the minimal differences explained by the distinct kinematic properties of the two samples. \\

The same analysis can be carried out for $c$-tagging, with the results displayed in Figure~\ref{fig:DL1dshapc}. As discussed for $b$-tagging, the most important features are again the \gls{dips} probabilities with $p_c$ ranking first and contributing the most to $D_c$. Interestingly, the ranking of features is roughly the same as for $D_b$, with most features that had a positive impact on $D_b$ when taking larger values now hurting $D_c$. This is the case for most of the JetFitter and \gls{sv1} variables. Defaulting behaviour of these algorithms, occurring when the conditions of a jet do not pass certain requirements, often has a positive effect on $D_c$ as expected. Again, the IPxD family of features score low, indicating the limited importance of their contributions to the output because the information is better provided by \gls{dips}. This anti-correlation behaviour of sub-algorithms to the $D_c$ discriminant is expected, these methods having been primarily designed to help $b$-tagging. 

\subsection{Training of DL1d on Variable Radius Jets for Run 3}\label{sec:VRdl1dTrain}
As for \gls{dips}, changing the jet definition from PFlow to \gls{vr}-jets is expected to have a large impact on the performance of the methods described here. Building on from the \gls{vr}-trained \gls{dips} model introduced in Section \ref{chapter:dipsVRtrain}, this section presents the training of \gls{dl1d} for \gls{vr}-jets. The datasets are similar to those of Section \ref{chapter:dipsVRtrain}. The \gls{vr}-trained \gls{dl1d} was trained for 300 epochs with no signs of overtraining. Its performance here is compared to the PFlow version introduced in the previous section, as well as the R21 \gls{dl1r} version trained on \gls{vr}-jets too and a pre-release \gls{gn1} trained on 20 million \gls{vr}-jets. 

\vspace{-0.5cm}
\begin{figure}[h!]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDL1d/ROC/ttb.png}
    \caption{$t\bar{t}$, $f_c = 0.018$ for DL1d.}
    \label{fig:dl1dVRROCtt}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDL1d/ROC/zpb.png}
    \caption{$Z'$, $f_c = 0.018$ for DL1d.}
    \label{fig:dl1dVRROCzp}
  \end{subfigure} \\
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDL1d/ROC/ttbupf.png}
    \caption{$t\bar{t}$, $f_c = 0.1$ for DL1d.}
    \label{fig:dl1dVRROCttc}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDL1d/ROC/zpbupf.png}
    \caption{$Z'$, $f_c = 0.1$ for DL1d.}
    \label{fig:dl1dVRROCzpc}
  \end{subfigure}
  \caption{ROC curves for $b$-tagging. Top row uses $f_c = 0.018$ for DL1d, and bottom row $f_c = 0.1$ (GN1 $f_c = 0.05$ everywhere). The VR-jets DL1d model is in blue, a pre-release VR-trained GN1 in orange, R21 DL1r trained on VR-jets in green, and the PFlow DL1d in red.}
  \label{fig:dl1dVRROC}
\end{figure}

\paragraph{}A clear benefit from retraining on the dedicated \gls{vr}-jet sets is observed in the \gls{roc} curves of Figures~\ref{fig:dl1dVRROC} and \ref{fig:dl1dVRROCgrav}, with the \gls{vr}-\gls{dl1d} outperforming the PFlow version for all $b$- and $c$-tagging efficiencies considered. Introducing \gls{dips} in the \gls{dl1} architecture has a significant impact on the performance of the tagger and greatly overmatches the \gls{rnnip} contribution. This is further highlighted by Table~\ref{tab:max-perf-dl1dVR} reporting the rejections obtained at different \gls{wp} of typical interest in analyses. \\

\begin{figure}[h!]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDL1d/ROC/grb.png}
    \caption{DL1d $f_c = 0.018$.}
    \label{fig:dl1dVRROCgr}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDL1d/ROC/grbupf.png}
    \caption{DL1d $f_c = 0.1$.}
    \label{fig:dl1dVRROCgrc}
  \end{subfigure}
  \caption{ROC curves for $b$-tagging. Similar to Figure~\ref{fig:dl1dVRROC} for the graviton process.}
  \label{fig:dl1dVRROCgrav}
\end{figure}

As shown in Table~\ref{tab:max-perf-dl1dVR}, the specifically \gls{vr}-trained \gls{dl1d} outperforms the PFlow version with the flavour fraction parameter for $b$-tagging $f^b_c$ changed from 0.018 (which is used for the PFlow model) to 0.1. For $c$-tagging, a clear gain in light-rejection comes at a cost of a lower $b$-rejection which can also be corrected by an appropriate change of the flavour fraction parameter for $c$-tagging $f^c_b$, currently set at 0.2 for both \gls{dl1d} models. As highlighted in Figure~\ref{apfig:DL1dVRscanf} of Appendix \ref{ap-DL1dVR}, displaying flavour fractions scans for $b$- and $c$-tagging, this choice of $f^c_b$ is indeed suboptimal for the 30\% \gls{wp}. 

\begin{table}[h]
  \begin{center}
      \begin{tabular}{C{1.5cm}|cc|cc|cc} 
      	 \hline \hline
          \multicolumn{7}{c}{$b$-tagging}\\ \hline
          & \multicolumn{2}{c|}{$t\bar{t}$} & \multicolumn{2}{c|}{$Z'$} & \multicolumn{2}{c}{Graviton} \\
          WP & $c$-rej  & light-rej & $c$-rej  & light-rej & $c$-rej  & light-rej  \\ \hline
          60\%  & +20\% &  +6\% & +14\% & +83\% & +19\% & +72\%  \\ 
          70\%  & +18\% &  +9\% & +14\% & +65\% & +16\% & +57\%  \\ 
          77\%  & +13\% & +15\% & +13\% & +56\% & +14\% & +51\%  \\ 
          85\%  &  +1\% & +25\% & +11\% & +45\% & +12\% & +40\%  \\ \hline
          \multicolumn{3}{c}{} \\
           \hline  \hline
           \multicolumn{7}{c}{$c$-tagging}\\ \hline
          & \multicolumn{2}{c|}{$t\bar{t}$} & \multicolumn{2}{c|}{$Z'$} & \multicolumn{2}{c}{Graviton} \\ 
          WP & $b$-rej  & light-rej & $b$-rej  & light-rej & $b$-rej  & light-rej  \\ \hline
          25\%   & -20\% & +137\% & -17\% & +90\% & -17\% & +80\% \\
          30\%   & -25\% & +114\% & -21\% & +73\% & -19\% & +66\% \\
          40\%   & -29\% &  +99\% & -23\% & +53\% & -22\% & +48\% \\
          50\%   & -29\% &  +80\% & -24\% & +39\% & -22\% & +35\% \\ \hline \hline
      \end{tabular}
    \caption{The change in background flavour rejection of \gls{vr}-trained \gls{dl1d} relative to the PFlow trained \gls{dl1d} at various tagging efficiencies, both trained on the new release. Top: $b$-tagging ($f^b_c = 0.1$ and 0.018 for the \gls{vr} and PFlow training); bottom: $c$-tagging ($f^c_b = 0.2$).}
    \label{tab:max-perf-dl1dVR}
  \end{center}
\end{table}

While this physics-motivated architecture optimisation moving from an \gls{rnn}-based to a Deep Set-based track analyser improves the efficiency of the hierarchical model, a clear gain in performance is accessible through the more radical modification of the architecture that is adopted for the \gls{gn1} model. This is a classical observation in the world of machine learning: the vast amount of low-level noisy data can be better exploited by sophisticated architecture than by using a simple model fed a few highly engineered and reconstructed features, even when these are physically motivated. \gls{gn1} is not based on any physics principles. As shown in the next section, the tracks themselves contain enough of the rich physics signature required to unlock the label of the jet they compose. 
