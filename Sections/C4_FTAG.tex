\chapter{\color{oxfordblue} Flavour Tagging}\label{chap-ftag}
\ChapFrame

\textit{
This chapter is focused on an essential task for the ATLAS experiment: disentangling which specific quark flavour should be associated with a jet, an association called flavour tagging. This chapter introduces a computational method to tag jets, as labelled by the flavour of the initial parton. In particular, the different algorithms and techniques relevant to this task that have been developed concurrently with this thesis project are reviewed, including the DIPS, DL1d, GN1, and GN2 models as well as early studies on the hyperparameter optimisation of GN2.
}

\section{Heavy-Flavour Jet Tagging}
A fundamental ingredient in any ATLAS analysis is the ability to correctly identify particles in the aftermath of a collision, from $\tau$-leptons, to $b$- and $c$-quarks, and gluons $g$. Having well-calibrated and optimally performing $b$- and $c$-tagging tools is of primary importance in studies of the Higgs boson's couplings to $b$- and $c$-quarks. It is also critical for top quark measurements and in many searches for physics beyond the Standard Model. As described by the theory of \gls{qcd}, colour-charged particles, such as a $b$- or a $c$-quark, undergo hadronisation to form collections of colour-neutral hadrons. These hadrons, mostly $B$ for $b$-quark and $D$ for $c$-quark, are quasi-stable and further decay in the volume of the detector. Such a succession of decays leaves a collection of particles within a cone oriented in the direction of the original parton, a recognisable pattern referred to as a \textit{jet}. By analysing the complex structure of jets, the flavour of the original decaying particles can be determined. Jets are labelled based on the species of hadrons found: a $b$-jet must contain at least one $b$-hadron, a $c$-jet at least one $c$-hadron and no $b$-hadron, and if none of these hadrons are found the jet is said to be a light-jet, thereby grouping $u$-, $d$-, and $s$-quarks with gluons $g$. This process is known as \textit{flavour tagging}, and the tool used for this identification is called a \textit{flavour tagger}. The focus of this chapter is on the development of novel taggers to identify $b$- and $c$-jets for the ATLAS experiment during the 2020-2024 period, spanning the end of Run 2 analyses (2015-2018) and the beginning of Run 3 (2022-2026). 

\subsection{Decay Topology}
When a $b$-quark is produced, such as in the aftermath of a hard scattering from a proton-proton collision, it quickly undergoes the process of hadronisation to neutralise its free colour charge. This process, which brings the initial free quarks and gluons to a final state of hadrons and leptons, is intrinsically non-perturbative and can only be described using phenomenological models of fragmentation \cite{Webber:419784}. The family of $b$-hadrons consists of different combinations of a bottom quark $b$ with one or more lighter quarks. These include the $B$-mesons, mainly $B^0=d\bar{b}$, $B^-=\bar{u}b$, $B^+=u\bar{b}$, as well as the strange and charmed $B$-mesons, and baryons such as the $\Lambda_b^0=udb$ \cite{ATL-PHYS-PUB-2014-008}. For $b$-quarks, the hadronisation process is hard, and most ($\sim$ 75\%) of the quark's momentum is transferred to the $b$-hadron \cite{Webber:419784}. \\

Tagging $b$-jets benefits from a particularly advantageous configuration: $b$-quarks are the lightest element of the third generation and must decay through a weak interaction flavour-changing process. Because of the relatively small value of the \gls{ckm} matrix element $|V_{bc}|$, decay processes involving a $b \rightarrow c$ transition are suppressed, resulting in $b$-hadrons having a characteristically long proper lifetime $\tau_B \approx 1.5$ ps, corresponding to a proper decay length $c\tau_{B} \sim 450$ $\mu$m \cite{Tanabashi:2018oca}. In the laboratory frame, considering a boost of the $b$-hadron given by a Lorentz $\gamma$ factor ($\gamma > 1$) in the high-energy limit, where $\beta = v/c \approx 1$, the distance travelled is \[d = \gamma \beta c \tau_B \approx \gamma c \tau_B.\] In this high-energy limit, $\gamma \approx E_B / m_B$ and the $B$-hadron rest mass is in the range of 5 to 6 GeV. Consequently, a 50 GeV $b$-hadron decays at a distance of $d \approx 4.5$ mm from the primary vertex, which can be resolved using current detector technology. This distance increases with rising jet $p_T$, and, at $p_T \sim$ 250 GeV, even surpasses the first detector layer of the \gls{ibl} located at a radius of 33 mm from the centre of ATLAS, as shown in Figure~\ref{fig:bhaddecay}. The location of the hadron decay, called the \glsreset{sv}\gls{sv}, can often be reconstructed with the ATLAS detector \cite{Aad:2019aic}. Some important variables describing the decay of hadrons are the \glsreset{ip}\glspl{ip} $d_0$ and $z_0$ of the tracks left by charged particles originating from the \gls{sv}. As shown in Figure~\ref{fig:bjet}, $d_0$ and $z_0$ are the transverse and longitudinal distances from the primary vertex to the perigee of the track. For a $b$-jet, the \glspl{ip} can be large due to the long lifetime of the associated hadron. On average, a $b$-hadron decays into 4 or 5 charged stable particles \cite{ATL-PHYS-PUB-2014-008}. Another characteristic of $b$-jets is the likely presence of leptons in the jet cone, as approximately 40\% of $b$- and $c$-hadron decays are semi-leptonic \cite{Tanabashi:2018oca}. \\

\begin{figure}[h!]
\center
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Images/FTAG/intro/jetIm.png}
  \caption{Representation of a $b$-jet \cite{bjetimage}.}
  \label{fig:bjet}
\end{minipage}
%\begin{minipage}{0.48\textwidth}
%  \centering
%  \includegraphics[width=\textwidth]{Images/FTAG/intro/bhaddecay.png}
%  \caption{$b$-hadron decay radius as a function of jet $p_T$ reconstructed for $b$-jets in a $Z'$ events with the IBL and pixel %layers indicated, from \cite{VanStroud:2869719}. Error bars show the standard deviation of $L_{xy}$ in each $p_T$ bin.} 
%  \label{fig:bhaddecay}
%\end{minipage}
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Images/FTAG/intro/bhaddecay2ada.png}
  \caption{$b$-hadron (black circles) and $D$-hadron (empty circles) decay distance as a function of jet $p_T$ in simulated $Z'$ events, adapted from \cite{ATL-PHYS-PUB-2018-025}. The blue and orange dashed lines indicate the locations of the \gls{ibl} and first Pixel layer.} 
  \label{fig:bhaddecay}
\end{minipage}
\end{figure}

While $b$-jets benefit from an advantageous topology, tagging $c$-jets at ATLAS proves more challenging as they are at an intermediate mass scale between light- and heavy-flavour jets. A $c$-jet must contain at least one $c$-hadron, from either a $D$-meson (e.g., $D^+=c\bar{d}$, $D^-=d\bar{c}$, $D^0=c\bar{u}$) or a $c$-baryon (e.g., $\Lambda_c^+=udc$). The average decay length for charged (neutral) $D$-mesons, $c\tau_D \sim 300$ $(100)$ $\mu$m \cite{Tanabashi:2018oca}, is smaller than for $b$-hadrons and is harder to resolve with the currently deployed tracker, as highlighted in Figure~\ref{fig:bhaddecay}. The decay chain of $b$-hadrons often includes a $c$-hadron, making a clean separation of $c$-jets from $b$-jets harder. Compared to $b$-jets, $c$-jets have a lower final state average charged particle multiplicity of 4. This allows $\tau$-jets to be easily mistaken for $c$-jets, as these leptons can hadronically decay into a similar number of particles and leave a jet signature in the detector. However, tagging $c$-jets is becoming particularly important due to the focus on the challenging $H \rightarrow c\bar{c}$ search \cite{Aaboud:2018fhh, Collaboration:2721696, arXiv:2205.05550}, as presented in the analysis of Chapter~\ref{chap-VH}. 

\subsection{Flavour Tagging at ATLAS}
In ATLAS, a choice was made to centrally develop a tagger to be used throughout the Collaboration. The tagger simultaneously performs $b$- and $c$-tagging, and the software stack and methods are continuously improved to meet the requirements of the physics program. Currently, all studied approaches rely on deep learning methods due to their vastly superior effectiveness. As such, various models have been introduced, which can be split into two generations. 
\begin{enumerate}
  \item The DL1 generation consists of \gls{dl} models built in a hierarchical way. These methods rely on high-level features reconstructed by subalgorithms based on physics variables, such as the tracks \glspl{ip}, and the reconstruction of secondary vertices \cite{ATL-PHYS-PUB-2015-022}. The most important models in this family are those including a \gls{dl} submodel to analyse tracks using either a \gls{rnn} approach for \gls{dl1r} \cite{ATLAS:2017bcq}, leveraging the \gls{rnnip} subtagger \cite{ATL-PHYS-PUB-2017-003}, and a Deep Set approach for \gls{dl1d}, leveraging the \gls{dips} subtagger \cite{ATL-PHYS-PUB-2020-014}. At the time of writing this thesis, this last tagger is the ATLAS state-of-the-art calibrated tagger \cite{ATL-SOFT-PUB-2021-001}. Algorithms from this generation were primarily developed for the end of Run 2 of the ATLAS experiment \cite{atlas:FTAGRUN2}, with \gls{dl1d} developed just before the start of Run 3.
  \item The GN taggers are built on more advanced deep learning methods that go beyond the hierarchical approach of the DL1 generation. These models directly analyse tracks and jet information using a unique and powerful architecture. The GN generation is based either on a full \glsreset{gat}\gls{gat} for \textit{\gls{gn1}}, or a transformer encoder for \textit{\gls{gn2}} \cite{ATL-PHYS-PUB-2022-027, ATL-PLOT-FTAG-2023-01, duperrin2023flavour}. The streamlined algorithm pipeline greatly simplifies maintenance and reduces the turnaround time for modifications, making the process of updating the taggers faster and easier to tailor to specific applications. The GN taggers greatly outperform the DL1 models and represent a promising area of progress for future analyses requiring precise flavour jet tagging. At the time of writing, \gls{gn2} is being calibrated and integrated into the ATLAS software stack \cite{ATL-SOFT-PUB-2021-001}.  
\end{enumerate}

\begin{figure}[h!]
  \center
  \includegraphics[width=0.8\textwidth]{Images/FTAG/storyFtag.png}
  \caption{Comparison of the performance of flavour tagging models introduced through the years \cite{ATL-PLOT-FTAG-2023-01}. Light (cyan) and $c$-jet (green) rejections (inverse of the mistagging efficiency) are plotted for different taggers at a fixed $b$-jet tagging efficiency of 70\% on a $t\bar{t}$ evaluation set. The multiplicative factors in the bars are with respect to the bare DL1 model performance.} 
  \label{fig:storyFtag}
\end{figure}

A historical perspective on the evolution of performance attained with the different taggers mentioned is presented in Figure~\ref{fig:storyFtag}, showing a remarkable and consistent improvement in light-jet and $c$-jet rejections at a fixed $b$-tagging efficiency of 70\%, as evaluated on a $t\bar{t}$ simulated dataset. The analysis presented in Chapter \ref{chap-VH} was conducted from 2021 to 2024 and was therefore restricted to the tools and methods available to the experimental team during this period. As such, due to the need to calibrate the GN taggers, as explained later in Section \ref{chap-calibration} of this chapter, the analysis was constrained to using the DL1 generation. The taggers described in this chapter have now all been integrated into the ATLAS software \cite{ATL-SOFT-PUB-2021-001}. 

\subsection{Datasets}\label{ftagdatasets}
ATLAS analyses cover a $p_T$ spectrum that spans a wide range of energies. To train models capable of performing over this large phase space, two training datasets are typically combined and they are described in this section. The datasets simulate proton-proton collisions at a centre-of-mass energy of $\sqrt{s}$ = 13 TeV. The lower $p_T$ phase space is filled with simulated \gls{sm} $t\bar{t}$ events, where both top quarks decay into a $W$ boson and a $b$-quark and one of the $W$ bosons decays leptonically. A \gls{bsm} $Z'$ process is used for the higher-momentum region. The latter simulates a modified $Z$ boson with an increased mass to generate a flat jet $p_T$ spectrum up to 6 TeV. These $Z'$ bosons decay in similar proportions into pairs of $b$-, $c$-, and light-jets. All simulations include realistic effects present in the real data, such as \glsreset{pu}\gls{pu} that is modelled with an average value of $ \langle\mu\rangle = 40$. Other effects included in the simulations are the detector response from prior and posterior bunch crossings (out-of-time \gls{pu}), as well as the activity from the rest of the underlying event. \\

Events in the $t\bar{t}$ sample are simulated using \textsc{POWHEGBOX V2} generators at Next-to-Leading Order (NLO) in the strong coupling constant $\alpha_s$ \cite{PaoloNason_2004, StefanoFrixione_2007, StefanoFrixione_20072, POWHEGBOX}. The hard scattering matrix element is computed for proton-proton collisions using the \textsc{NNPDF3.0NNLO} set of \glsreset{pdf}\glspl{pdf} \cite{PDFLHCrun2}, and the simulated hard scattering events are interfaced with \textsc{PYTHIA 8.230} \cite{SJOSTRAND2015159} using the A14 parameter tune \cite{ATL-PHYS-PUB-2014-021} and the \textsc{NNPDF2.3LO} \glspl{pdf} for the parton shower, hadronisation, and underlying event simulations \cite{BALL2013244}. Studies in Refs. \cite{ATL-PHYS-PUB-2016-020, ATL-PHYS-PUB-2020-023} showed that these choices suitably model the top quark $p_T$ and the number of additional jets in the event, with the $h_{\textrm{damp}}$ parameter set to 1.5 times the mass of the top quark $m_{\textrm{top}} = 172.5$ GeV. The $Z'$ events are fully simulated with \textsc{PYTHIA 8.212}, the A14 tune, and the \textsc{NNPDF2.3LO} \glspl{pdf}. The decays of $b$- and $c$-hadrons are simulated using \textsc{EvtGEN} v1.6.0 \cite{LANGE2001152}. \\

The detector reconstruction effect and the modelling of the interaction between long-lived hadrons and the detector material are simulated with a dedicated software \cite{ATLASSimulationInfra} built on GEANT4 \cite{Agostinelli:602040}. Jets are selected in the phase space region defined by $|\eta| < 2.5$ and $p_T > 20$ GeV, with no overlap allowed with prompt generator-level $e$ or $\mu$ from the $W$ decay. Pile-up contamination is further reduced by an additional selection using the Jet Vertex Tagger algorithm (introduced in Section \ref{sec-atlas-jets}) at a tight operating point for jets with $p_T < 60$ GeV and $|\eta| < 2.4$ \cite{ATLAS-CONF-2014-018}. Tracks are associated with a jet using a $\Delta R$ association cone with a width that decreases with $p_T$, such that $\Delta R \approx 0.45$ at $p_T =$ 20 GeV and $\Delta R \approx 0.25$ at $p_T = 200$ GeV. Tracks within the cone of several jets are associated with the jet that minimises the angular distance $\Delta R(\textrm{track, jet})$. The label of the jet is inferred from the presence of a truth-level hadron within the cone $\Delta R(\textrm{hadron, jet}) < 0.3$ centred on the jet axis.

\section{DL1 Generation of Taggers: DL1r \& DL1d}
This generation of taggers is built with a hierarchical approach, combining low-level algorithms that are independently optimised into a final \gls{dnn} network of a few layers to output the predictions. Several low-level modules are not based on deep learning but instead directly implement physics-inspired algorithms. The low-level algorithms consist of \cite{atlas:FTAGRUN2, Paganini:2289214}:
\begin{itemize}
  \item \textit{\gls{ip} Likelihood Discriminants}: IP2D and IP3D - jointly denoted as IPxD - are likelihood ratio templates assigning flavour-discriminating weights based on the transverse and global impact parameter significances\footnote{Corresponding to the reweighted \gls{ip} variables by their respective uncertainties.} $S_{d_0}$ (35 bins) and $S_{z_0}$ (20 bins) of the tracks, and 14 bins of track categorisation in addition for IP3D \cite{ATLAS:2017bcq}. For the three main flavours, this results in $35 \times 20 \times 14 \times 3 = 29,400$ final bins, with each probability computed per track. The likelihood assigned to the jet assumes that all tracks are independent, and is therefore calculated as the product of the individual track likelihoods. A discriminant is derived from the conditional log-likelihood, e.g., $D^b_{IP3D,f} = \sum_{i \in \textrm{tracks}} \log (p_b^i / p_f^i)$ to discriminate $b$-jets from $f$-jets ($f= c$ or light) \cite{ATL-PHYS-PUB-2015-022}.
  \item \textit{Track Collection Analyser}: either with \gls{rnnip} \cite{ATL-PHYS-PUB-2017-003} or \gls{dips} \cite{ATL-PHYS-PUB-2020-014}. These are deep learning approaches to extract discrimination information from the set of tracks associated with a jet. They importantly do not assume that tracks are independent. These taggers are described in detail later in this chapter. 
  \item \textit{\gls{sv1}}: combines a secondary vertex finder and a tagger to provide flavour discrimination information \cite{atlas:FTAGRUN2}. The former, based on the \textsc{VKalVrt} vertex reconstruction package \cite{Kostyukhin:685551}, returns a list of candidate secondary vertices with measured quantities assigned to each vertex. The latter derives jet weights based on discriminative variables and computes properties of the \gls{sv}, such as its mass. 
  \item \textit{Jet Fitter}: is a vertexing algorithm based on a Kalman filter to reconstruct the topology and fit the decay chain \gls{pv} $\rightarrow$ $B$ $\rightarrow$ $D$, assuming that the direction of the final $D$-hadron tends to be collinear with that of the $B$ \cite{atlas:FTAGRUN2, ATL-PHYS-PUB-2018-025}. 
\end{itemize}

\begin{figure}[h!]
  \centerline{
  \begin{minipage}[c]{0.4\textwidth}
      \includegraphics[scale=0.5]{Images/Algorithms}
    \end{minipage}
  \begin{minipage}[c]{0.6\textwidth}
      \caption{The algorithms for flavour tagging in the DL1 family. High-level taggers are in dark blue, track-based taggers in light blue, and vertex taggers in white.}
      \label{fig:algo}
    \end{minipage}
  }
\end{figure}

The outputs of these low-level algorithms, as well as certain jet-level variables such as $p_T$ and $\eta$, are then passed as input to a high-level tagger consisting of a fully-connected \gls{nn} called \gls{dl1r} or \gls{dl1d}, depending on whether \gls{rnnip} or \gls{dips} is used. The input vector contains 45 features. This high-level tagger outputs three scores $p_X$ for the analysed jet, corresponding to the $b$-, $c$-, or light-flavour (summarised as $u$) probabilities, such that $p_b + p_c + p_u = 1$. A $b$-tagging discriminant $D_b$ is then derived by computing a scaled log-likelihood ratio 
\begin{equation}\label{bdisc}
D_b = \log \frac{p_b}{f^b_c \times p_c + (1 - f^b_c) \times p_u},
\end{equation}
where $f^b_c$ is the $c$-fraction, a parameter that can be adjusted to tweak the relative importance of the rejected flavours. The analogous $c$-tagging discriminant $D_c$, which relies on the $b$-fraction parameter $f^c_b$, is
\begin{equation}\label{cdisc}
D_c = \log \frac{p_c}{f^c_b \times p_b + (1 - f^c_b) \times p_u}.
\end{equation}

A jet is $X$-tagged if the $D_X$ discriminant score is above a set threshold constant $c_{WP}$, defining a \textit{\gls{wp}} with a unique configuration of signal and background (mistagging) efficiencies. In this context, the efficiency $\epsilon^X_Y$ for $Y$-flavour jets to be $X$-tagged and the corresponding rejection $\mathcal{R}^X_Y$ are defined as
\begin{equation}
\epsilon^X_Y = \frac{N^{X-tagged}_{Y-jets}}{N_{Y-jets}} \quad \textrm{and} \quad \mathcal{R}^X_Y = \frac{1}{\epsilon^X_Y},
\end{equation}
where $N^{X-tagged}_{Y-jets}$ and $N_{Y-jets}$ are the number of $X$-tagged $Y$-flavoured jets and the total number of $Y$-flavoured jets, respectively. The $f$-rejection is the inverse mistagging efficiency of flavour $f$.  \\

These high-level models are trained on \gls{mc} simulated data samples, as described in Section \ref{ftagdatasets}, and need to be calibrated on real data to deliver an unbiased estimate by deriving scale factors that correct the predictions for each jet, as detailed in Section \ref{chap-calibration}. Uncertainties are derived on the predicted score and passed along to analyses using the tagger. The novel algorithm of this generation introduced in this work is the \gls{dl1d} tagger, which relies on the new \gls{dips} subtagger to extract correlations between the tracks.  

\subsection{RNNIP}
The \gls{rnnip} tagger runs on arbitrary-length input sequences composed of track features, ordered by the absolute transverse \gls{ip} significance $|S_{d_0}|$, to extract tagging information from correlations between tracks \cite{ATL-PHYS-PUB-2017-003}. The vector of track features, described in Table~\ref{tab:rnnipVar}, includes the transverse and longitudinal impact parameter significances, the jet $p_T$ fraction, the distance between the tracks and the jet axis, and a learnt 2D embedding of track quality \cite{Paganini:2289214}. \gls{rnnip} outputs a probability $p_X$ for the jet to belong to flavour $X$ $\in$ [$b$, $c$, light, $\tau$]. 

\begin{table}[h!]
  \begin{center}
      \begin{tabular}{C{3cm}|C{12cm}} 
      	 \hline \hline
          Track Variables & Description  \\ \hline \hline
          $S_{d_0}$      & Lifetime signed transverse \gls{ip} significance $d_0 / \sigma_{d_0}$, with $d_0$ the transverse \gls{ip} and $\sigma_{d_0}$ the error on $d_0$. The sign is positive (negative) if the perigee is in front of (behind) the \gls{pv} with respect to the jet direction. \\ \hline
          $S_{z_0}$      & Lifetime signed longitudinal \gls{ip} significance $z_0 / \sigma_{z_0}$, with $z_0$ the longitudinal \gls{ip} and $\sigma_{z_0}$ the error on $z_0$. A sign is assigned as per the prescription of $S_{d_0}$. \\ \hline
          $p_T^{\textrm{frac}}$   & Fraction of the reconstructed jet $p_T^{\textrm{jet}}$ carried by the track $p_T^{\textrm{frac}} = p_T^{\textrm{track}} / p_T^{\textrm{jet}}$. \\ \hline
          $\Delta R$(track, jet) & Geometric distance in 2D angle between the track direction and jet axis $\Delta R = \sqrt{(\phi_{\textrm{track}} - \phi_{\textrm{jet}})^2 + (\eta_{\textrm{track} - \eta_{\textrm{jet}}})^2}$. \\ \hline
          Category       & 2D representation of the track quality learnt by an embedding layer. The categorisation is based on the number of observed, expected, and missing hits in the different layers of the tracker (silicon pixel and strip detectors) \cite{ATL-PHYS-PUB-2015-022}.  \\ \hline
      \end{tabular}
    \caption{Track variables passed to the initial version of the \gls{rnnip} model \cite{ATL-PHYS-PUB-2017-003}. Later versions removed the category embedding and added the per-track hit information shown in Table~\ref{tab:dipsVar}.}
    \label{tab:rnnipVar}
  \end{center}
\end{table}

The architecture of \gls{rnnip}, depicted in Figure~\ref{fig:rnnipModel}, is an \gls{rnn}-based model leveraging an \gls{lstm} core - an \gls{ml} unit introduced in Chapter \ref{sec:RNN}. The arbitrary-length sequence fed as input is mapped by the \gls{lstm} cell with a 100-unit hidden layer into a 50-dimensional vector. This vector is then processed by a 20-unit fully-connected feed-forward neural network, outputting the per-flavour probabilities by computing the softmax of the last layer's output. To avoid overfitting, a dropout value of 0.2 is applied to the \gls{lstm} cell. \\


\begin{figure}[h!]
  \center
  \includegraphics[scale=0.6]{Images/FTAG/rnnip_structure.png}
  \caption{Diagram of the \gls{rnnip} tagger \cite{Paganini:2289214}. The input consists of track features augmented with an embedding of track categories. Tracks are then ordered by absolute transverse \gls{ip} significance and fed through an \gls{lstm} core. The unrolled sequence from this \gls{lstm} is padded to a fixed size and processed by a \gls{dnn} to output the per-flavour probabilities.} 
  \label{fig:rnnipModel}
\end{figure}

\gls{rnnip} is designed to capture correlations among the tracks of a jet, an important insight explicitly missing from the \gls{ip}-based discriminant of IP2D and IP3D due to the factorisation of the likelihood. Some degree of correlation is expected among tracks, as these can emerge from the same secondary or tertiary vertex of the displaced decays in $b$-jets and $c$-jets. \gls{rnnip} removes the cumbersome procedure of building likelihood templates, which requires a large amount of data to scale to finer bin resolutions and is computationally expensive due to the number of bins scaling exponentially with the number of variables. \gls{rnnip} is effective at building a discriminant, delivering superior performance to the \gls{ip}-based approaches with only $\sim$ 40\% of the parameters - 11,636 trainable parameters for \gls{rnnip} \cite{Paganini:2289214}.

\subsection{DIPS}
\begin{figure}[h!]
  \center
  \includegraphics[scale=0.6]{Images/FTAG/dips_structure.png}
  \caption{Diagram of the \gls{dips} flavour tagger \cite{ATL-PHYS-PUB-2020-014}. The input consists of a set of $N$ tracks, each represented by a feature vector. Each track is embedded by a \gls{dnn} track network $\Phi$ into a fixed-dimensional vector. All embedded track vectors are then pooled by an element-wise summation to a fixed-size vector. The last step is to process this vector with another \gls{dnn} jet network $F$ outputting the per-flavour probabilities. The number and width of layers presented here correspond to the nominal architecture.} 
  \label{fig:dipsModel}
\end{figure}
The \gls{dips} tagger is based on the Deep Set architecture \cite{NIPS2017f22e4747}, as depicted in Figure~\ref{fig:dipsModel}, and provides an alternative to \gls{rnnip} for modelling the correlations among an arbitrary number of tracks \cite{ATL-PHYS-PUB-2020-014}. As introduced in Section \ref{chapter-GNN}, such a model is composed of two fully-connected feed-forward neural networks. A first \gls{dnn} called the \textit{track network} $\Phi$ maps each track feature vector — similar to the input of \gls{rnnip} — to a latent space representing the nodes of a graph. The representations of each track in this latent space are then pooled by a simple summation operation - representing the unweighted edges of a fully-connected graph - and given as input to a secondary \gls{dnn}, called the \textit{jet network} $F$. The latter outputs the predicted probability $p_X$ for the jet to belong to flavour $X$ $\in$ [$b$, $c$, light, $\tau$]. This final network represents the global attribute of the graph $u$, in the notation of Section \ref{chapter-GNN}. In summary, \gls{dips} computes the following equation on the set of track features ${ p_i }$ ($i = 1, ..., N$) for an arbitrarily-sized jet of $N$ tracks
\begin{equation}
  DIPS( \{p_1, ..., p_N \} ) = F\left( \sum_{i=1}^N \Phi(p_i) \right).
\end{equation}
The separation of the computation into a per-track embedding and a per-jet processing after a size-independent pooling, performed by the summation operator, allows the model to process unordered sets of variable size. The input track features are described in Table~\ref{tab:dipsVar}, with only the top 15 tracks ranked by decreasing $S_{d_0}$ considered. \\

\begin{table}[h]
  \begin{center}
      \begin{tabular}{C{3cm}|C{12cm}} 
      	 \hline \hline
          Variables & Description  \\ \hline
          $S_{d_0}$      & Lifetime signed transverse \gls{ip} significance $d_0 / \sigma_{d_0}$, with $d_0$ the transverse \gls{ip} and $\sigma_{d_0}$ the error on $d_0$. The sign is positive (negative) if the perigee is in front (behind) the \gls{pv} with respect to the jet direction. \\ \hline
          $S_{z_0}$      & Lifetime signed longitudinal \gls{ip} significance $z_0 / \sigma_{z_0}$, with $z_0$ the longitudinal \gls{ip} and $\sigma_{z_0}$ the error on $z_0$. A sign is assigned as per the prescription of $S_{d_0}$. \\ \hline
          $\log p_T^{\textrm{frac}}$   & Logarithm of the fraction of the reconstructed jet $p_T^{\textrm{jet}}$ carried by the track $\log p_T^{\textrm{frac}} = \log p_T^{\textrm{track}} / p_T^{\textrm{jet}}$. \\ \hline
          $\log \Delta R$(track, jet) & Logarithm of the geometric distance in 2D angle between the track direction and jet axis $\log \Delta R = \log \sqrt{(\phi_{\textrm{track}} - \phi_{\textrm{jet}})^2 + (\eta_{\textrm{track} - \eta_{\textrm{jet}}})^2}$. \\ \hline
          IBL hits      & Number of hits recorded in the \gls{ibl} - 0, 1, or 2. \\ \hline
          PIX1 hits       & Number of hits in the innermost pixel layer, after the \gls{ibl} - 0, 1, or 2.  \\ \hline
          Shared IBL hits & Number of hits in the \gls{ibl} that are shared by more than one track. \\ \hline
          Split IBL hits  & Number of split hits in the \gls{ibl}, that are created by multiple charged particles. \\ \hline
          nPixHits        & Total number of hits in all the pixel layers.\\ \hline
          Shared pixel hits & Number of shared hits in the pixel layers.\\ \hline
          Split pixel hits  & Number of split hits in the pixel layers.\\ \hline
          nSCTHits          & Total number of hits in the \gls{sct} layers. \\ \hline
          Shared SCT hits   & Number of shared hits in the \gls{sct} layers.\\ \hline \hline
      \end{tabular}
      \caption{Track variables passed to the \gls{dips} model and later versions of the \gls{rnnip} model \cite{ATL-PHYS-PUB-2020-014}. Compared to the initial \gls{rnnip} variables of Table~\ref{tab:rnnipVar}, the $p_T^{\textrm{frac}}$ and $\Delta R$ are passed as log values to reduce the magnitude of the long tail observed at large values and to improve the training time. Shared hits are hits used by multiple tracks without being classified as split by a dedicated cluster-splitting \gls{nn} \cite{ATLAS-tracks-algo}.}
    \label{tab:dipsVar}
  \end{center}
\end{table}

This approach has several advantages over \gls{rnnip}, mainly the physically-motivated permutation invariance of the input and the improved training and evaluation time, as the track embedding performed by $\Phi$ can be massively parallelised on \glspl{gpu}. These motivations translate into an appreciable performance delivered by \gls{dips}, which globally outperforms \gls{rnnip} while operating at a reduced computational cost \cite{ATL-PHYS-PUB-2020-014}. The performance can be assessed from Figure~\ref{fig:dipsrnnipPerf}, presenting the \gls{roc} curves for the baseline training of \gls{dips} and \gls{rnnip} in terms of light- and $c$-rejection for $b$-jet tagging on a $t\bar{t}$ evaluation sample. \\

\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{Images/FTAG/dipsrnnipL.png}
      \caption{Light-rejection.} 
      \label{fig:dipsrnnipPerfL}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{Images/FTAG/dipsrnnipC.png}
      \caption{$c$-rejection.} 
      \label{fig:dipsrnnipPerfC}
  \end{subfigure}
  \caption{Light- (left) and $c$-rejection (right) as a function of $b$-jet tagging efficiency for \gls{rnnip} (green) and \gls{dips} (purple) \cite{ATL-PHYS-PUB-2020-014}. The curves and error bands show the mean and standard deviation of the rejections for 5 trainings per algorithm.}
  \label{fig:dipsrnnipPerf}
\end{figure} 

%The optimisation campaign focused on three aspects of the \gls{dips} network: the architecture of the two \gls{nn}, the track selection, and the set of track features used as input in addition to those of Table~\ref{tab:dipsVar}. Regarding architecture, a grid search over various possible values for the number of layers in $\Phi$ and $F$, the number of nodes, and the dimension of the track embedding space showed no significant performance change. The selected architecture is:
%\begin{itemize}
%  \item Track network $\Phi$: three layers of 100, 100, and 128 units applied to each track. 
%  \item Jet network $F$: four layers of size 100, 100, 100, 30 before the final output of size dictated by the number of %flavours to identify (3 or 4 typically). 
%\end{itemize}
%To regularise and avoid overfitting, both batch normalisation and dropout were tested with the former observed to give %better results. \\ 


%  \begin{figure}[h!]
%    \centering
%    \begin{subfigure}[b]{0.48\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{Images/FTAG/dipsOptL.png}
%        \caption{Light-rejection.} 
%        \label{fig:dipsOptRocL}
%    \end{subfigure}
%    \hfill
%    \begin{subfigure}[b]{0.48\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{Images/FTAG/dipsOptL.png}
%        \caption{$c$-rejection.} 
%        \label{fig:dipsOptRocC}
%    \end{subfigure}
%    \caption{Light- (left) and $c$-rejection (right) as a function of $b$-jet tagging efficiency for different \gls{dips} model, with the baseline (nominal) \gls{dips} in purple, the loosened track selection in blue, and the fully optimised \gls{dips} in orange, from \cite{ATL-PHYS-PUB-2020-014}. The curve and error bands show, respectively, the mean and standard deviation of the rejections for 5 trainings per algorithm with different initial random seeds. The bottom panel shows the ratio to the baseline \gls{dips}, showing a clear performance gain from the two-step optimisation procedure at all $b$-jet efficiency considered.}
%    \label{fig:dipsOptRoc}
%  \end{figure} 

The training times on the same \gls{gpu} hardware for a 48k-parameter \gls{dips} model is 78 $\pm$ 4 seconds per epoch, while a 47k-parameter \gls{rnnip} requires roughly thrice as much, 241 $\pm$ 14 seconds per epoch \cite{ATL-PHYS-PUB-2020-014}. The faster training time allowed the Collaboration to focus on optimisation studies of the hyperparameters. An important observation was that loosening the track selection criteria led to an improvement in performance. For \gls{rnnip}, IP2D, and IP3D, the selected tracks must pass the following quality selection: $\geq$ 8 hits in the silicon layers, $\leq$ 2 missing hits in the silicon layers, $\geq$ 1 hit in the pixel detector, $\leq$ 1 hit shared by multiple tracks, $p_T > 1$ GeV, $|d_0| < 1$ mm, and $|z_0 \sin\theta| < 1.5$ mm. For \gls{dips}, a looser track selection increasing the acceptance of the last three cuts is preferable, modifying the nominal selection in the following way: $p_T$ > 0.5 GeV, $|d_0| < 3.5$ mm, and $|z_0 \sin\theta| < 5$ mm \cite{ATL-PHYS-PUB-2020-014}. Loosening the selection and keeping the top 25 tracks ranked by decreasing $S_{d_0}$ to capture more tracks from heavy-flavour decays gives a significant improvement in performance for jets with $p_T < 250$ GeV for \gls{dips}. From a machine learning viewpoint, a larger set of input information with more noise can still be beneficial if the underlying model is complex enough to capture useful features in the noisy data, that would otherwise be removed by a more stringent selection. Some studies on interpreting the performance of \gls{dips} are summarised in Appendix~\ref{app-DIPS-perf}. % The performance gain for loosened selection \gls{dips} is displayed in the \gls{roc} curves of Figure~\ref{fig:dipsOptRoc}. Clear benefits are also obtained by adding additional track features as input on top of the looser selection, as shown by the orange curve of Figure~\ref{fig:dipsOptRoc}, which plots the performance of a loose track selection \gls{dips} trained with the per-track \gls{ip} parameters $d_0$ and $z_0$ in addition to the features of Table~\ref{tab:dipsVar}.\\

\subsection{Training DIPS with Variable Radius Jets for Run 3}\label{chapter:dipsVRtrain}
The physics programme of the ATLAS Collaboration covers a wide range of analyses, targeting different topologies and processes at various energies. Regarding flavour tagging, a particularly relevant aspect is the energy or transverse momentum of the jets to be labelled. Flavour taggers are extremely sensitive to the dynamics of the underlying event. At higher energies, corresponding to higher momenta of the hadronised quark or gluon, the jet constituents originating from the decaying parton tend to be more collimated. This topology confounds tracks and blends the rich internal jet dynamics in the measured signature, making track separation and secondary or tertiary vertex identification more challenging. Analyses targeting jets from hadronic or semi-leptonic decays of heavy particles, such as the top $t$-quark, Higgs $H$, or the gauge vector $W$/$Z$ bosons, have to study such highly energetic boosted jets.  \\

So far in this chapter, jets have always referred to the objects reconstructed by the anti-$k_T$ algorithm with a fixed radius $R = 0.4$ applied to PFlow objects, as introduced in Chapter \ref{chapter-ATLAS}. This reconstruction method proves robust in the hadron collider setting as it both leads to suitably shaped jet structure and \gls{pu}-resistant properties. The fixed radius however becomes a hurdle to reconstruct boosted jets, as the average radius of a jet decreases with energy due to the collimation of the jet contents. The angular separation $\Delta R$ between the products of a decaying particle $X$ of large mass $m_X$ scales inversely to the transverse momentum \cite{ATLAS:largeRjet}: 
\begin{equation}\label{eq:sizeJet}
  \Delta R \approx \frac{2 m_X}{p_T^X}.
\end{equation}
At low $p_T^X$, the individually produced particles from the decay are sufficiently separated to be reconstructed as individual objects, hence the \textit{resolved} regime label \cite{ATLAS:2016hcf}. For example, a non-boosted Higgs decaying to a $b\bar{b}$ pair can be reconstructed as two $b$-jets with small $R$ = 0.4. At higher momentum, however, the content of the decay is collimated and overlaps: this is the \textit{boosted} regime. The decaying particle $X$ in such a regime is typically reconstructed as a single large-radius jet catching the different underlying jets, for example with the anti-$k_T$ method with radius $R = 1.0$. Using such a large radius overestimates the size of boosted jets which are easily contaminated by \gls{pu}, as well as the underlying event and initial-state radiation.  \\

Another approach to reconstruct jets for boosted objects decay is the \glsreset{vr}\gls{vr} jet algorithm \cite{vrJetPaper}, as introduced in Chapter \ref{chapter-ATLAS}. \gls{vr} jets have a size that scales with the inverse of the reconstructed jet momentum, thus correctly following Equation \ref{eq:sizeJet}. Such a significant change to the jet reconstruction has an impact on algorithms learning structure from the jet contents, as is the case of all deep learning-based taggers presented in this chapter. These models must therefore be fine-tuned for this new jet type for optimal performance, which is the focus of this section. For the \gls{vr}-training, the dataset is composed of three samples simulating proton-proton collisions at $\sqrt{s} = 13$ with the following fractions:
\begin{itemize}
  \item 85\% of jets are sampled from the $t\bar{t}$ with a maximal $p_T$ of 400 GeV. At least one of the $W$ bosons from the $t$-quark is required to decay leptonically.
  \item 7.5\% are sampled from $Z'$ events, where an exotic boson $Z'$ decays as $Z' \rightarrow q\bar{q}$, with a variable $Z'$ mass to generate a flat $p_T$ spectrum extending the $p_T$-range of the jets studied up to 4 TeV. These jets are required to have a $p_T > 150$ GeV.
  \item 7.5\% are sampled from a simulated graviton process to also extend the range to higher momenta. These jets are required to have a $p_T > 150$ GeV.
\end{itemize}

The simulation process is similar to that introduced in Section \ref{ftagdatasets}. Appendix Figure~\ref{apfig:vrjetdist} displays the jet $p_T$ and $|\eta|$ distributions for the hybrid sample as well as the individual samples it is based upon, for a total of 40 $\times$ $10^6$ jets per flavour in \{$b$, $c$, light\}. \\

To reach such high statistics, importance sampling with replacement is used to upsample the limited number of $c$-jets while using all available $b$-jets and downsampling light-jets. A particularity of the processing is the requirement for the $p_T$ and $|\eta|$ spectra to be equally distributed for all jet flavours so that these features, arising from inherent physical effects in the specific processes simulated, cannot be used by the model to discriminate among flavours. Jets of different flavours are selected to match a specific target distribution. The importance sampling weights are derived by first computing the ratio of the targeted 2D distribution to the per-flavour one. Weights above 1 indicate jets in that bin have to be oversampled, while values lower than 1 indicate they should be downsampled. Jets are iteratively resampled until the distribution of each flavour matches the target distribution. As displayed in Appendix Figure~\ref{apfig:vrjetdisth} for which the target is $b$-jets, the constructed distributions have the same $p_T$ and $|\eta|$ distributions for all flavours. This work introduced the first implementation of the importance sampling method, which is now widely used to develop flavour tagging tools leveraging the full statistical power of the simulations. \\ 

For the \gls{vr} \gls{dips} version, the optimised \gls{dips} model with 62,167 learnable parameters from the previous section is trained for 200 epochs on 4 Quadro RTX 8000 \glspl{gpu}. The learning rate starts at 0.001 and is reduced by a factor of 0.8 on plateaus of 3 epochs, with a batch size of 15k jets, batch normalisation, and a dropout rate of 0.1 for the $F$ network. The model at the epoch giving the smallest loss on a validation set of 300k jets as well as the best light- and $c$-rejections at a fixed 77\% $b$-tagging efficiency is selected. Figure~\ref{fig:dipsVRROC} show the \gls{roc} curves for $b$- and $c$-tagging of the best \gls{dips} model on \gls{vr} jets (blue), as well as some comparison to the \gls{dips} model trained on PFlow jets (orange) and \gls{rnnip} trained on \gls{vr} jets from the previous software release (green). These \gls{roc} plots show, on the $x$-axis, the $b$-tagging efficiency ($\epsilon^b_b$) versus, on the $y$-axis, the rejection $\mathcal{R}^b_Y$ for $Y \in$ [$c$, light], or equivalently for $c$-tagging swapping $b \leftrightarrow c$. The graviton \gls{roc} curve is presented Appendix Figure \ref{fig:dipsVRROCgrav}.

\newpage

\begin{figure}[h!]
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    %\includegraphics[scale=0.43]{Images/FTAG/VRDips/ROC/ttb.png}
    \includegraphics[width=\textwidth]{Images/FTAG/VRDips/ROC/ttb.png}
    \caption{$b$-tagging on \ttb.}
    \label{fig:dipsVRROCtt}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDips/ROC/zpb.png}
    \caption{$b$-tagging on $Z'$.}
    \label{fig:dipsVRROCzp}
  \end{subfigure} \\
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDips/ROC/ttc.png}
    \caption{$c$-tagging on \ttb.}
    \label{fig:dipsVRROCttc}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/FTAG/VRDips/ROC/zpc.png}
    \caption{$c$-tagging on $Z'$.}
    \label{fig:dipsVRROCzpc}
  \end{subfigure}
  \caption{ROC curves for $b$-tagging and $c$-tagging on 300k jets test samples of \ttb\ (left) and $Z'$ (right). Models displayed are the \gls{vr} jets \gls{dips} in blue, the PFlow-trained \gls{dips} in orange, and \gls{rnnip} trained on \gls{vr} jets from the previous software release in green.}
  \label{fig:dipsVRROC}
\end{figure}

Training \gls{dips} on a dedicated set of \gls{vr} jets improves performance compared to relying on the PFlow-trained version, as observed by comparing the blue (\gls{vr}-trained \gls{dips}) to orange curves (PFlow-trained \gls{dips}). At a $b$-tagging efficiency of 77\%, the light-rejection of the PFlow-trained \gls{dips} is approximately 40\% lower than the \gls{vr}-trained \gls{dips}. However, the $c$-rejection does not benefit as much, being either on par or even worse for the \gls{vr}-trained \gls{dips} on the $t\bar{t}$ samples. This difference in performance indicates an inappropriate choice of the $f_c$ value for the $b$-tagging discriminant of the \gls{vr}-trained \gls{dips}. This parameter can be optimised to balance background rejections using \textit{flavour fraction scans}, an example of which is shown later in Figure \ref{fig:DL1dscanf}. However, \gls{dips} probabilities are not used directly in a discriminant but rather passed on in the high-level algorithm \gls{dl1d}; hence this optimisation is reserved for the final model as presented in Section~\ref{sec:VRdl1dTrain}. Figures \ref{fig:dipsVRROCttc} and \ref{fig:dipsVRROCzpc} lead to similar conclusions for $c$-tagging. % A so-called \textit{flavour fraction scan}, displaying the rejections at a fixed tagging efficiency for different values of the flavour fraction, can lead to a better choice for a balanced improvement in both background jet rejections.

\subsection{Training DL1d and DL1r with PFlow Jets for Run 3}
This work presents the first study of the retraining of \gls{dl1r} on a new ATLAS software release for Run 3 of the \gls{lhc}, and the first training of \gls{dl1d} including the \gls{dips} subtagger in a high-level flavour tagging tool. Other novelties of this work include the possible inclusion of $\tau$-jets in the DL1 model's predictions and the importance sampling technique to process high-statistics training datasets introduced in the previous section. The interest in including $\tau$-jets stems from their tendency to be misclassified as $c$-jets when hadronically decaying, as both particles commonly leave three to four particles in the detector. The new taggers are observed to efficiently identify $\tau$-jets, thereby providing a new way to perform $\tau$-identification and improving $c$-jet tagging.\\ % However, due to the widespread use of the \gls{ftag} algorithms and the difficulties arising in calibrating a tagger with excellent rejection against $\tau$-jets, these are not included in the default version of the tagger nor the results shown here, but are actively under study for the new generation of tagger in the GN family. \\ % Problem: reference to tau tagging but no plots ... add them?

Two samples, the $t\bar{t}$ and $Z'$, are simulated in proton-proton collisions at $\sqrt{s} = 13$ TeV and combined in the datasets, as described in Section \ref{ftagdatasets}. For both samples, PFlow jets are reconstructed using the anti-$k_T$ algorithm with a radius of $R = 0.4$. These two samples are combined into a single \textit{hybrid} sample to train the taggers, with 70\% of the total number of jets coming from $t\bar{t}$ and the remaining from the $Z'$ sample. The $t\bar{t}$ and $Z'$ samples cover, respectively, low- and high-$p_T$ regions based on a reconstructed $b$-hadron $p_T$ separation threshold of 250 GeV for $b$-jets and a jet $p_T$ of 250 GeV for non-$b$-jets. They are resampled to have the same $p_T-|\eta|$ distributions. The relative proportion of each sample was chosen to avoid any discontinuity in the $p_T$ spectrum at their junction, as shown in Figure~\ref{fig:distTraining}. The total statistics available for training is $25 \times 10^{6}$ jets per flavour. The final evaluation of the performance of a trained tagger is performed on separate test sets of both processes and unfolded over the flavours. The $t\bar{t}$ and $Z'$ samples for validation and testing are each made of 1 million jets and are not downsampled to have the same [$p_T - \eta$] distribution nor the same yield of different flavours. \\

\begin{figure}[h!]
  \center
  \includegraphics[width=0.48\textwidth]{Images/FTAG/DL1d/ptdist.png}
  \includegraphics[width=0.48\textwidth]{Images/FTAG/DL1d/etadist.png}
  \caption{The $p_T$ (left - in MeV) and $|\eta|$ distributions of the resampled $b$-, $c$-, and light-jets in, respectively, blue, orange, and green. The three sets are resampled to have the same $p_T-|\eta|$ 2D distributions. The flat $p_T$ spectrum extending up to several TeV is due to the exotic $Z'$ process generated with varying masses, starting at 150 GeV. The large peak at lower $p_T$ is due to the $t\bar{t}$ process. These sets each have 8.3 million jets per flavour.} 
  \label{fig:distTraining}
\end{figure}

%ATLAS flavour tagging tools are widely used across the Collaboration. It is therefore essential for the taggers not to learn specific features of the processes simulated but to focus on the inherent differences between the studied flavours to generalise to other processes. An effective way to limit the importance of the simulated processes is to downsample the hybrid sample in [$p_T - \eta$] bins to have the same number of $b$-, $c$-, and light-jets in each 2D bin. This removes the distinction of kinematic phase space between each flavour due to the process-specific physics. To avoid biasing the output of the tagger towards the most likely flavours in the process, each jet flavour is also required to be equally likely in the training set, a requirement satisfied by having the same yield of $b$-, $c$-, and light-jets. Applying this technique, the total statistics available for the R22 training is of $25 \times 10^{6}$ jets per flavour for training. The $t\bar{t}$ and $Z'$ samples for validation and testing are each made of 1 million jets and are not downsampled to have the same [$p_T - \eta$] distribution nor the same yield of different flavours: they represent a realistic distribution of the underlying processes. The main limitation when downsampling is the $c$-jets statistics, as all $c$-jets from the $t\bar{t}$ process are selected which limits the amount of $b$- and light-jet that can be taken. This process is extremely wasteful, using only 17\% (11\%) of all available $b$-jets (light-jets) in the $t\bar{t}$ sample.\\

Training is performed with the TensorFlow-based \cite{tensorflow2015-whitepaper} \textsc{Umami} software \cite{UmamiCite} for 300 epochs with a variable learning rate schedule and the default network structure adopted in the previously released \gls{dl1r}: 8 fully connected \gls{nn} layers of decreasing sizes [256, 128, 60, 48, 36, 24, 12, 6] with \gls{relu} activation, leading to a final softmax layer producing the predicted probabilities for each flavour. The models from the epoch offering the best combined results in terms of $b$-tagging efficiency and rejection from $b$-jets on the validation set are selected for further analysis. Every training run converged to a fixed set of performance values, with no overtraining occurring. Several modifications to the model architecture, list of input variables, and preprocessing and training procedures were explored, with no significant gains observed. The conclusion drawn from the lack of improvements from these attempts is that models built on this simple \gls{dnn} structure with such a large dataset are already saturating their performance. To establish a meaningful benchmark for the newly trained taggers, the performance of the then-recommended \gls{dl1r} tagger, trained and evaluated on an analogous set of samples from the previous software release, is included in the following results under the label \textit{Recom. \gls{dl1r}}. \\

Figure~\ref{fig:DL1dtt} presents the \gls{roc} curves for the $t\bar{t}$ (left) and $Z'$ (right) test samples for $b$-tagging. The two bottom subplots present the ratio of the $c$-jet and light-jet rejection curves relative to the recommended \gls{dl1r} ones. Figure~\ref{fig:DL1dz} shows similar plots for $c$-tagging, with respect to $b$-jet and light-jet rejections. The important conclusion is the clear gain obtained by replacing \gls{rnnip} with \gls{dips}. Both the $b$- and $c$-tagging performance of \gls{dl1d} dominate the \gls{dl1r} versions, with a significant improvement in background flavour rejection for all tagging efficiencies considered, as summarised in Table~\ref{tab:max-perf}. The largest performance improvement is obtained for $b$-tagging on the $t\bar{t}$ process at lower jet momenta. This latter point indicates a dynamic behaviour of the \gls{dips} subtagger that can be traced back to the looser jet selection. Higher momentum jets are more likely to have a larger set of tracks, and these tracks tend to be closer to each other due to relativistic boosting. The looser selection forces the \gls{dips} model to sift through a noisier set of tracks. This results in smaller gains in performance at higher momentum, while an improvement is obtained at lower momentum due to the good geometric separation and smaller initial set. \\

\begin{table}[h]
  \begin{center}
      \begin{tabular}{C{2cm}|cc} 
      	 \hline \hline
          \multicolumn{3}{c}{$b$-tagging on $t\bar{t}$} \\ \hline
          WP & $c$-rejection  & light-rejection  \\ \hline
          60\%   & +26\% & +73\% \\ 
          70\%   & +19\% & +56\% \\ 
          77\%   & +12\% & +41\% \\ 
          85\%   & +7\%   & +32\% \\ \hline
          \multicolumn{3}{c}{} \\
           \hline  \hline
           \multicolumn{3}{c}{$c$-tagging on $t\bar{t}$} \\ \hline
          WP & $b$-rejection  & light-rejection  \\ \hline
          25\%   & +26\% & +5\% \\
          30\%   & +25\% & +9\% \\
          40\%   & +22\% & +12\% \\
          50\%   & +18\% & +15\% \\ \hline \hline
      \end{tabular}
      \quad
       \begin{tabular}{C{2cm}|cc} 
       	 \hline  \hline
          \multicolumn{3}{c}{$b$-tagging on $Z'$} \\ \hline
          WP & $c$-rejection  & light-rejection  \\ \hline
          60\%   & +19\% & +43\% \\
          70\%   & +10\% & +32\% \\
          77\%   & +9\%  & +26\% \\
          85\%   & +6\%  & +19\% \\ \hline
          \multicolumn{3}{c}{} \\
           \hline  \hline
           \multicolumn{3}{c}{$c$-tagging on $Z'$} \\ \hline
          WP & $b$-rejection  & light-rejection  \\ \hline
          25\%   & +12\% & +22\% \\
          30\%   & +11\% & +19\% \\
          40\%   & +8\%   & +14\% \\
          50\%   & +7\%   & +10\% \\ \hline  \hline
      \end{tabular}
    \caption{The change in background flavour rejections of \gls{dl1d} relative to \gls{dl1r} at various tagging efficiencies, both trained on the new release. Top: $b$-tagging ($f^b_c = 0.018$); bottom: $c$-tagging ($f^c_b = 0.2$); left: $t\bar{t}$; right: $Z'$.}
    \label{tab:max-perf}
  \end{center}
\end{table}

\begin{figure}[h!]
  \centering
  \centerline{
  \includegraphics[scale=0.45]{Images/FTAG/DL1d/ROC/ttb.png}
  \includegraphics[scale=0.45]{Images/FTAG/DL1d/ROC/zpb.png}
  }
  \caption{Performance for $b$-tagging with a flavour fraction of $f^b_c = 0.018$. Left: $t\bar{t}$; right: $Z'$. Top: ROC curves; centre: ratio of $c$-jet rejection from $b$-jets relative to DL1r; bottom: same ratio for light-jet rejection. The recommended DL1r from the previous release is shown in blue. The new release DL1d is shown in orange and GN1 is in green.}
  \label{fig:DL1dtt}
  \bigskip
  \centerline{
  \includegraphics[scale=0.45]{Images/FTAG/DL1d/ROC/ttc.png}
  \includegraphics[scale=0.45]{Images/FTAG/DL1d/ROC/zpc.png}
  }
  \caption{Performance for $c$-tagging with a flavour fraction of $f^c_b = 0.2$. Left: $t\bar{t}$; right: $Z'$. Top: ROC curves; centre: ratio of $b$-jet rejection from $c$-jets relative to DL1r; bottom: same ratio for light-jet rejection. The recommended DL1r from the previous release is shown in blue. The new release DL1d is shown in orange and GN1 is in green.}
  \label{fig:DL1dz}
\end{figure}
\vspace*{\fill}

\clearpage

%Both the $b$- and $c$-tagging performance of \gls{dl1d} dominate the \gls{dl1r} versions, with a significant improvement in background flavour rejection for all tagging efficiencies considered, as summarised in Table~\ref{tab:max-perf}. The largest performance improvement is obtained for $b$-tagging on the $t\bar{t}$ process at lower jet momenta. This latter point indicates a dynamic behaviour of the \gls{dips} subtagger that can be traced back to the looser jet selection. Higher momentum jets are more likely to have a larger set of tracks, and these tracks tend to be closer to each other due to relativistic boosting. The looser selection forces the \gls{dips} model to sift through a noisier set of tracks. This results in smaller gains in performance at higher momentum, while an improvement is obtained at lower momentum due to the good geometric separation and smaller initial set.  \\

The $b$-jet rejection from $c$-jets \gls{roc} curve in Figure~\ref{fig:DL1dz} traces an elbow at high $c$-jet efficiencies. These values correspond to a set of $b$-jets that do not overlap with the $c$-jets $c$-tagging discriminants distributions, as shown in Figure \ref{fig:scoreDL1dz}. These ``background`` jets are easily removed from the core set of ``signal'' jets due to inherent differences between the flavours and the discrete nature of some subtaggers used. The background rejections of the various taggers for $b$-tagging ($c$-tagging) as a function of the jet transverse momentum $p_T$ at an inclusive $b$-efficiency of 70\% ($c$-efficiency of 30\%) per region displayed are shown in Figure~\ref{fig:ptDL1dtt} (Figure~\ref{fig:ptDL1dz}). Throughout the $p_T$ range considered, \gls{dl1d} outperforms the \gls{dl1r} tagger. The low $p_T$ $b$-jet rejection from $c$-jets is noticeably better for the newly trained tagger compared to \gls{dl1r}. The discontinuity in the rejections between the two processes arises from the inclusive $b$-tagging efficiency being computed per region and not exclusively for the whole range.  

%\clearpage
%\vspace*{\fill}
\vspace{-0.3cm}
\begin{center}
  \begin{figure}[h!]
  %\vspace{-0.2cm} 
  \centerline{
  \includegraphics[scale=0.5]{Images/FTAG/DL1d/ROC/scores_DL1_ttbar_300.png}
  \includegraphics[scale=0.5]{Images/FTAG/DL1d/ROC/scores_DL1_zp_300.png}
  }
  \vspace{-0.3cm}
  \caption{\gls{dl1d} $b$-tagging discriminant distribution ($f_c = 0.018$) for the different jet flavours on $t\bar{t}$ (left) and $Z'$ (right).}
  \label{fig:scoreDL1dtt}
  \centerline{
  \includegraphics[scale=0.5]{Images/FTAG/DL1d/ROC/scores_DL1_ttbar_c_299.png}
  \includegraphics[scale=0.5]{Images/FTAG/DL1d/ROC/scores_DL1_zp_c_299.png}
  }
  \vspace{-0.3cm}
  \caption{\gls{dl1d} $c$-tagging discriminant distribution ($f_b = 0.2$) for the different jet flavours on $t\bar{t}$ (left) and $Z'$ (right).}
  \label{fig:scoreDL1dz}
  \end{figure}
\end{center}
%\vspace*{\fill}
\vspace{-0.8cm}
These results include a \gls{gnn}-based tagger that was in development at the time: \gls{gn1} \cite{ATL-PHYS-PUB-2022-027}. This model is based on a graph attention network directly processing low-level inputs, thereby diverging from the traditional ATLAS flavour tagging philosophy of combining low-level subtaggers into a high-level one, such as in \gls{dl1d}. As exemplified in Figures \ref{fig:DL1dtt} and \ref{fig:DL1dz}, the method significantly improves performance and is explored in further detail in Section~\ref{chap:GN}.

\clearpage
%
\begin{center}
\begin{figure}[h!]
\vspace{-0.6cm}
\centerline{
  \includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/ttbc.png}
  \includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/ttbu.png}
}
\centerline{
  \includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/zpbc.png}
  \includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/zpbu.png}
}
\caption{Background flavour rejections at a fixed $b$-tagging efficiency of 70\% (per region shown) for the various taggers. Top: $t\bar{t}$; bottom: $Z'$; left: $c$-rejection; right: light-rejection. For each plot, the bottom panel presents the ratio relative to the recommended \gls{dl1r}.}
\label{fig:ptDL1dtt}
\bigskip
\centerline{
\includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/ttcb.png}
\includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/ttcu.png}}
\centerline{
\includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/zpcb.png}
\includegraphics[scale=0.425]{Images/FTAG/DL1d/perpT/zpcu.png}
}
\caption{Background flavour rejections at a fixed $c$-tagging efficiency of 30\% (per region shown) for the various taggers. Top: $t\bar{t}$; bottom: $Z'$; left: $b$-rejection; right: light-rejection. For each plot, the bottom panel presents the ratio relative to the recommended \gls{dl1r}.}
\label{fig:ptDL1dz}
\end{figure}
\end{center}

\vspace{-0.5cm} % temp! Might remove
The \gls{dl1d} tagger has been quickly integrated into the ATLAS software thanks to its similarities with \gls{dl1r}. Its fast calibration has led to its rapid introduction to the Collaboration and deployment in early Run 3 analyses \cite{ATLAS-CONF-2022-070}. To exploit the full potential of the trained model and cater to the specific needs of individual analyses, several working points are centrally defined and calibrated. An important parameter to control the relative importance of the jet classes to be rejected with the discriminants of Equations \ref{bdisc} and \ref{cdisc}, light and $c$ for $b$-tagging and light and $b$ for $c$-tagging, are the flavour fractions $f_c$ and $f_b$. Naturally, there is a trade-off: for $b$-tagging, a larger $f_c$ value favours better $c$-rejection at the cost of degrading the light-rejection. To measure this dependency, flavour fractions scans are performed at a fixed $b$-tagging ($c$-tagging) efficiency of 77\% (30\%) in Figure~\ref{fig:DL1dscanfb} (Figure~\ref{fig:DL1dscanfc}). \\

% here
%\vspace{-1cm}
\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{\textwidth}
      \centering
      \includegraphics[width=0.49\textwidth]{Images/FTAG/DL1d/extra_plots/contour_fraction_ttbar_300.pdf}
      \includegraphics[width=0.49\textwidth]{Images/FTAG/DL1d/extra_plots/contour_fraction_zp_300.pdf}
      \caption{Flavour fraction $f_c^b$ scan for $b$-tagging: left is $t\bar{t}$ and right $Z'$ test samples.} 
      \label{fig:DL1dscanfb}
  \end{subfigure}\\
  \begin{subfigure}[b]{\textwidth}
    \centering % NEED TO CORRECT THE WP for the c-tagging case
    \includegraphics[width=0.49\textwidth]{Images/FTAG/DL1d/extra_plots/contour_fraction_c_ttbar_299.pdf}
    \includegraphics[width=0.49\textwidth]{Images/FTAG/DL1d/extra_plots/contour_fraction_c_zp_299.pdf}
    \caption{Flavour fraction $f_b^c$ scan for $c$-tagging: left is $t\bar{t}$ and right $Z'$ test samples.} 
    \label{fig:DL1dscanfc}
\end{subfigure}
  \caption{The flavour fraction scans of the DL1d model. The chosen values are marked on the curves, displaying on the $y$-axis the $c$-rejection ($b$-rejection) for $b$-tagging ($c$-tagging) vs the light-rejection on the $x$ axis at a fixed operating point of 77\% (33\%). Increasing $f_c$ ($f_b$) shifts the marker upwards along the curves. }
  \label{fig:DL1dscanf}
\end{figure} 

An effective technique to measure the relative importance of the different variables is to quantify their contributions to the output using Shapley values. This technique calculates the average contribution of each input to the output \cite{Rozemberczki2022TheSV}. Figures~\ref{fig:DL1dshapb} and \ref{fig:DL1dshapc} present the outcome of applying this framework, as proposed in Ref. \cite{NIPS2017_7062}, to approximate the Shapley values of the inputs to the $b$-tagging $D_b$ and $c$-tagging $D_c$ discriminants of \gls{dl1d}, respectively. These so-called \textit{beeswarm} plots measure the impact of the evidence on the output of the model for each input feature. The plots display how each feature's Shapley value modifies the discriminant by moving from a prior background-data distribution expectation to the final model prediction using the real feature. A set of test data points of the targeted jet distributions are sampled and, for each, a prior expectation was randomly sampled for the initial test. The impact of using the real value in the prediction was then measured. Positive Shapley values indicate variables having an increasing effect on the discriminant, thereby helping either $b$- or $c$-tagging depending on the case considered. Each data point is coloured on a gradient scale from low feature value in blue to high feature value in red, and the dots pile up to indicate the density of the distribution. A feature that has more weight of its Shapley values distribution at larger values of the feature can be expected to help the model in identifying the main flavour of jets. Conversely, if the Shapley values are negative for large values of the feature, the feature value should be lowered for the model discriminant to improve. \\

%\begin{figure}[h!]
\begin{sidewaysfigure}
  \centering
  \includegraphics[scale=0.7]{Images/FTAG/DL1d/Shap/ttb.png}
  \includegraphics[scale=0.7]{Images/FTAG/DL1d/Shap/zpb.png}
  \caption{Shapley values of the different input variables of DL1d for $b$-tagging, $t\bar{t}$ on the left and $Z'$ on the right. High feature values are marked with red dots, while low feature values are marked with blue dots.} 
  \label{fig:DL1dshapb}
\end{sidewaysfigure} 

%\begin{figure}[h!]
\begin{sidewaysfigure}
  \centering
  \includegraphics[scale=0.7]{Images/FTAG/DL1d/Shap/ttc.png}
  \includegraphics[scale=0.7]{Images/FTAG/DL1d/Shap/zpc.png}
  \caption{Shapley values of the different input variables of DL1d for $c$-tagging, $t\bar{t}$ on the left and $Z'$ on the right. High feature values are marked with red dots, while low feature values are marked with blue dots.} 
  \label{fig:DL1dshapc}
\end{sidewaysfigure} 

Inspecting Figure~\ref{fig:DL1dshapb} reveals some interesting patterns in the \gls{dl1d} network for $b$-tagging. The most important family of features for this task are the \gls{dips} probabilities, with higher values of $p_b$ correctly identifying the jet as $b$ while higher values of $p_c$ and $p_{\textrm{light}}$ (noted $p_u$) have the opposite effect. The number of 2-track pairs from \gls{sv1} and some JetFitter variables - the mass of the vertex, the energy fraction and the number of tracks at the vertex - are also highlighted as important features. These observations are in line with the physics-based reasoning that $b$-jets are expected to have a large charged particle multiplicity, with the $b$-hadron taking most of the $b$-quark momentum. Some other interesting features to consider are the ones formatted as  ``algoName\_isDefaults'': they encode whether the base-method ``algoName'' is activated (0 - blue) or not and thus defaulting (1 - red) for each jet. Interestingly, most occurrences of a defaulting behaviour of \gls{sv1} and JetFitter are associated with a negative Shapley value, demonstrating the validity of the physics reasoning behind these methods and their active contributions to $b$-tagging. IPxD variables generally score low in the ranking, indicating these methods contribute little to the model predictions and can be safely removed, an observation confirmed by direct optimisation of the input feature set. Contrasting the Shapley values for $t\bar{t}$ (left) and $Z'$ (right), the same variables roughly rank in the same order, with the minimal differences explained by the distinct kinematic properties of the two samples. \\

The same analysis can be carried out for $c$-tagging, with the results displayed in Figure~\ref{fig:DL1dshapc}. As discussed for $b$-tagging, the most important features are again the \gls{dips} probabilities, with $p_c$ ranking first and contributing the most to $D_c$. Interestingly, the ranking of features is similar to that of $D_b$, with most features that had a positive impact on $D_b$ when taking larger values now negatively impacting $D_c$. This is the case for most of the JetFitter and \gls{sv1} variables. The defaulting behaviour of these algorithms, occurring when the conditions of a jet do not meet certain requirements, has as expected a positive effect on $D_c$. Again, the IPxD family of features scores low, indicating the limited importance of their contributions to the output now that this information is provided by \gls{dips}. This anti-correlation behaviour of subalgorithms to the $D_c$ discriminant is expected, as they were primarily designed to help $b$-tagging. 

\subsection{Training DL1d with Variable Radius Jets for Run 3}\label{sec:VRdl1dTrain}
As with \gls{dips}, changing the jet definition from PFlow to \gls{vr} jets is expected to have a large impact on the performance of the methods described here. Building on the \gls{vr}-trained \gls{dips} model introduced in Section \ref{chapter:dipsVRtrain}, this section presents the training of \gls{dl1d} for \gls{vr} jets. The datasets are similar to those in Section \ref{chapter:dipsVRtrain}. The \gls{vr}-trained \gls{dl1d} is trained for 300 epochs with no signs of overtraining. Its performance here is compared to the PFlow version introduced in the previous section, as well as a \gls{dl1r} version trained on \gls{vr} jets and a pre-release \gls{gn1} trained on 20 million \gls{vr} jets. \\

Table~\ref{tab:max-perf-dl1dVR} reports the rejections obtained at different \gls{wp} of typical interest in analyses. It highlights that retraining on the dedicated \gls{vr} jet sets leads to a significant improvement in performance. The \gls{vr}-\gls{dl1d} outperforms the PFlow version for all $b$- and $c$-tagging efficiencies considered, as highlighted by the \gls{roc} curves in Figures~\ref{fig:dl1dVRROC} and \ref{fig:dl1dVRROCgrav} in Appendix \ref{ap-DL1dVR}. Introducing \gls{dips} into the DL1 architecture has a significant impact on the performance of the tagger and greatly improves on \gls{rnnip}. The specifically \gls{vr}-trained \gls{dl1d} outperforms the PFlow version with the flavour fraction parameter for $b$-tagging $f^b_c$ changed from 0.018 (used for the PFlow model) to 0.1. For $c$-tagging, a clear gain in light-rejection comes at the cost of lower $b$-jet rejection, which can also be corrected by an appropriate change of the flavour fraction parameter for $c$-tagging $f^c_b$, currently set at 0.2 for both \gls{dl1d} models. As highlighted in Figure~\ref{apfig:DL1dVRscanf} of Appendix \ref{ap-DL1dVR}, which displays flavour fraction scans for $b$- and $c$-tagging, this choice of $f^c_b$ is indeed suboptimal for the 30\% \gls{wp}. \\

\begin{table}[h]
  \begin{center}
      \begin{tabular}{C{1.5cm}|cc|cc|cc} 
      	 \hline \hline
          \multicolumn{7}{c}{$b$-tagging}\\ \hline
          & \multicolumn{2}{c|}{$t\bar{t}$} & \multicolumn{2}{c|}{$Z'$} & \multicolumn{2}{c}{Graviton} \\
          WP & $c$-rej  & light-rej & $c$-rej  & light-rej & $c$-rej  & light-rej  \\ \hline
          60\%  & +20\% &  +6\% & +14\% & +83\% & +19\% & +72\%  \\ 
          70\%  & +18\% &  +9\% & +14\% & +65\% & +16\% & +57\%  \\ 
          77\%  & +13\% & +15\% & +13\% & +56\% & +14\% & +51\%  \\ 
          85\%  &  +1\% & +25\% & +11\% & +45\% & +12\% & +40\%  \\ \hline
          \multicolumn{3}{c}{} \\
           \hline  \hline
           \multicolumn{7}{c}{$c$-tagging}\\ \hline
          & \multicolumn{2}{c|}{$t\bar{t}$} & \multicolumn{2}{c|}{$Z'$} & \multicolumn{2}{c}{Graviton} \\ 
          WP & $b$-rej  & light-rej & $b$-rej  & light-rej & $b$-rej  & light-rej  \\ \hline
          25\%   & -20\% & +137\% & -17\% & +90\% & -17\% & +80\% \\
          30\%   & -25\% & +114\% & -21\% & +73\% & -19\% & +66\% \\
          40\%   & -29\% &  +99\% & -23\% & +53\% & -22\% & +48\% \\
          50\%   & -29\% &  +80\% & -24\% & +39\% & -22\% & +35\% \\ \hline \hline
      \end{tabular}
    \caption{The change in background flavour rejection of \gls{vr}-trained \gls{dl1d} relative to the PFlow trained \gls{dl1d} at various tagging efficiency working points, both trained on the new release. Top: $b$-tagging ($f^b_c = 0.1$ and 0.018 for the \gls{vr} and PFlow training); bottom: $c$-tagging ($f^c_b = 0.2$).}
    \label{tab:max-perf-dl1dVR}
  \end{center}
\end{table}

While the physics-motivated architecture optimisation moving from an \gls{rnn}-based to a Deep Set-based track analyser improves the efficiency of the hierarchical model, a clear gain in performance is achievable through the more radical modification of the architecture adopted for the \gls{gn1} model, as demonstrated in Figures \ref{fig:DL1dtt}, \ref{fig:DL1dz}, \ref{fig:dl1dVRROC}, and \ref{fig:dl1dVRROCgrav}. This is a common observation in the field of machine learning: the vast amount of low-level noisy data can be better exploited by sophisticated architectures than by using a simple model fed with a few highly engineered and reconstructed features, even when these are physically motivated. \gls{gn1} is not based on any specific physics principles. As shown in the next section, the tracks themselves contain enough of the rich physics signature required to determine the label of the jet they compose. 